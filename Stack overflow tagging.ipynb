{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ihs1Hb3RU93S"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rAZDkLNPU93Y"
   },
   "source": [
    "# Stack Overflow: Tag Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "5vLiHX5KnTvY",
    "outputId": "a9b85649-340a-405d-85a3-d74c2ff8ea4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive/My Drive/data\n"
     ]
    }
   ],
   "source": [
    "# Running in Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My\\ Drive/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72tNpKctnXjN"
   },
   "source": [
    "**Not doing EDA and other pre-processing. Directly working on the assignment. And lot of code is taken from original notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LCDUa4KxU97L",
    "outputId": "807d1420-1332-44d6-9055-cd340497e7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the databse:\n",
      "QuestionsProcessed\n"
     ]
    }
   ],
   "source": [
    "#http://www.sqlitetutorial.net/sqlite-python/create-tables/\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def checkTableExists(dbcon):\n",
    "    cursr = dbcon.cursor()\n",
    "    str = \"select name from sqlite_master where type='table'\"\n",
    "    table_names = cursr.execute(str)\n",
    "    print(\"Tables in the databse:\")\n",
    "    tables =table_names.fetchall() \n",
    "    print(tables[0][0])\n",
    "    return(len(tables))\n",
    "\n",
    "def create_database_table(database, query):\n",
    "    conn = create_connection(database)\n",
    "    if conn is not None:\n",
    "        create_table(conn, query)\n",
    "        checkTableExists(conn)\n",
    "    else:\n",
    "        print(\"Error! cannot create the database connection.\")\n",
    "    conn.close()\n",
    "\n",
    "sql_create_table = \"\"\"CREATE TABLE IF NOT EXISTS QuestionsProcessed (question text NOT NULL, code text, tags text, words_pre integer, words_post integer, is_code integer);\"\"\"\n",
    "create_database_table(\"Processed.db\", sql_create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FtgktWvU973"
   },
   "outputs": [],
   "source": [
    "def tags_to_choose(n):\n",
    "    t = multilabel_y.sum(axis=0).tolist()[0]\n",
    "    sorted_tags_i = sorted(range(len(t)), key=lambda i: t[i], reverse=True)\n",
    "    multilabel_yn=multilabel_y[:,sorted_tags_i[:n]]\n",
    "    return multilabel_yn\n",
    "\n",
    "def questions_explained_fn(n):\n",
    "    multilabel_yn = tags_to_choose(n)\n",
    "    x= multilabel_yn.sum(axis=1)\n",
    "    return (np.count_nonzero(x==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvjtTBZ6U98y"
   },
   "source": [
    "<h2>Modeling with less data points (0.5M data points) and more weight to title and 500 tags only</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "n0QKMrEwU98y",
    "outputId": "25b39117-3587-4951-9a43-971630c24097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the databse:\n",
      "QuestionsProcessed\n"
     ]
    }
   ],
   "source": [
    "sql_create_table = \"\"\"CREATE TABLE IF NOT EXISTS QuestionsProcessed (question text NOT NULL, code text, tags text, words_pre integer, words_post integer, is_code integer);\"\"\"\n",
    "create_database_table(\"Titlemoreweight.db\", sql_create_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_x-ETQJU99P"
   },
   "outputs": [],
   "source": [
    "#Taking 0.5 Million entries to a dataframe.\n",
    "write_db = 'Titlemoreweight.db'\n",
    "if os.path.isfile(write_db):\n",
    "    conn_r = create_connection(write_db)\n",
    "    if conn_r is not None:\n",
    "        preprocessed_data = pd.read_sql_query(\"\"\"SELECT question, Tags FROM QuestionsProcessed\"\"\", conn_r)\n",
    "conn_r.commit()\n",
    "conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "bc7hwHjBU99U",
    "outputId": "15aecde5-fdf8-4621-c2da-698987df2930"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dynam datagrid bind silverlight dynam datagrid...</td>\n",
       "      <td>c# silverlight data-binding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dynam datagrid bind silverlight dynam datagrid...</td>\n",
       "      <td>c# silverlight data-binding columns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>java.lang.noclassdeffounderror javax servlet j...</td>\n",
       "      <td>jsp jstl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>java.sql.sqlexcept microsoft odbc driver manag...</td>\n",
       "      <td>java jdbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>better way updat feed fb php sdk better way up...</td>\n",
       "      <td>facebook api facebook-php-sdk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                                 tags\n",
       "0  dynam datagrid bind silverlight dynam datagrid...          c# silverlight data-binding\n",
       "1  dynam datagrid bind silverlight dynam datagrid...  c# silverlight data-binding columns\n",
       "2  java.lang.noclassdeffounderror javax servlet j...                             jsp jstl\n",
       "3  java.sql.sqlexcept microsoft odbc driver manag...                            java jdbc\n",
       "4  better way updat feed fb php sdk better way up...        facebook api facebook-php-sdk"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Xk9V0azqU99X",
    "outputId": "381d6daf-6b62-4dc5-dab6-8419ebb4bb5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points in sample : 500000\n",
      "number of dimensions : 2\n"
     ]
    }
   ],
   "source": [
    "print(\"number of data points in sample :\", preprocessed_data.shape[0])\n",
    "print(\"number of dimensions :\", preprocessed_data.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oUpccCSkU99Z"
   },
   "source": [
    "**Converting string Tags to multilable output variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SWg_g1lNU99a"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary='true')\n",
    "multilabel_y = vectorizer.fit_transform(preprocessed_data['tags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbtD0Hx8U99c"
   },
   "source": [
    "**Selecting 500 Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_nMDxAIU99d"
   },
   "outputs": [],
   "source": [
    "questions_explained = []\n",
    "total_tags=multilabel_y.shape[1]\n",
    "total_qs=preprocessed_data.shape[0]\n",
    "for i in range(500, total_tags, 100):\n",
    "    questions_explained.append(np.round(((total_qs-questions_explained_fn(i))/total_qs)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "fggMk2IJU99f",
    "outputId": "7470e5b7-5b07-463b-c506-7e68729302ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with  5500 tags we are covering  99.157 % of questions\n",
      "with  500 tags we are covering  90.956 % of questions\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(questions_explained)\n",
    "xlabel = list(500+np.array(range(-50,450,50))*50)\n",
    "ax.set_xticklabels(xlabel)\n",
    "plt.xlabel(\"Number of tags\")\n",
    "plt.ylabel(\"Number Questions coverd partially\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# you can choose any number of tags based on your computing power, minimun is 500(it covers 90% of the tags)\n",
    "print(\"with \",5500,\"tags we are covering \",questions_explained[50],\"% of questions\")\n",
    "print(\"with \",500,\"tags we are covering \",questions_explained[0],\"% of questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VuJzfmNrU99i",
    "outputId": "ba7ed85e-4d6d-4438-fbd8-caf50d42ebac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of questions that are not covered : 45221 out of  500000\n"
     ]
    }
   ],
   "source": [
    "# we will be taking 500 tags\n",
    "multilabel_yx = tags_to_choose(500)\n",
    "print(\"number of questions that are not covered :\", questions_explained_fn(500),\"out of \", total_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsduwXTeU99k"
   },
   "outputs": [],
   "source": [
    "train_datasize = 400000\n",
    "x_train=preprocessed_data.head(train_datasize)\n",
    "x_test=preprocessed_data.tail(preprocessed_data.shape[0] - 400000)\n",
    "\n",
    "y_train = multilabel_yx[0:train_datasize,:]\n",
    "y_test = multilabel_yx[train_datasize:preprocessed_data.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "iZZDSH_VU99m",
    "outputId": "f6510c28-1f4d-4e0e-8eb2-dc6ce881ba82",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data : (400000, 500)\n",
      "Number of data points in test data : (100000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train data :\", y_train.shape)\n",
    "print(\"Number of data points in test data :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cow4e_y4U997"
   },
   "source": [
    "<h1>Assignments</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ry9fz7FmU998"
   },
   "source": [
    "<ol>\n",
    "    <li> Use bag of words upto 4 grams and compute the micro f1 score with Logistic regression(OvR) </li>\n",
    "    <li> Perform hyperparam tuning on alpha (or lambda) for Logistic regression to improve the performance using GridSearch  </li>\n",
    "    <li> Try OneVsRestClassifier  with Linear-SVM (SGDClassifier with loss-hinge)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDJ2PvnzU99o"
   },
   "source": [
    "<h3>Featurizing data with Count vectorizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "530e8tW9U99o",
    "outputId": "98375eda-3447-4beb-f3d0-ecb8d7f3bf1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:06:45.229803\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "vectorizer = CountVectorizer(min_df=0.00009, max_features=200000, \\\n",
    "                             tokenizer = lambda x: x.split(), ngram_range=(1,4))\n",
    "x_train_multilabel = vectorizer.fit_transform(x_train['question'])\n",
    "x_test_multilabel = vectorizer.transform(x_test['question'])\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "r9iDfzXIU99t",
    "outputId": "8c0cef11-0882-45ef-bb4f-88f07a9e7876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (400000, 95585) Y : (400000, 500)\n",
      "Dimensions of test data X: (100000, 95585) Y: (100000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train data X:\",x_train_multilabel.shape, \"Y :\",y_train.shape)\n",
    "print(\"Dimensions of test data X:\",x_test_multilabel.shape,\"Y:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmmnoy4XU99v"
   },
   "source": [
    "<h3>Applying Logistic Regression with OneVsRest Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GnHoxl5DU99w"
   },
   "outputs": [],
   "source": [
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l1'))\n",
    "classifier.fit(x_train_multilabel, y_train)\n",
    "predictions = classifier.predict(x_test_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "_L2Vz7WeDwMs",
    "outputId": "f1f8cb54-776b-4f82-bf67-a2cb11777fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 0.00001\n",
      "Accuracy : 0.09716\n",
      "Hamming loss  0.00580116\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2911, Recall: 0.4660, F1-measure: 0.3583\n",
      "Macro-average quality numbers\n",
      "Precision: 0.2061, Recall: 0.4068, F1-measure: 0.2653\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test_multilabel)\n",
    "\n",
    "print(\"For alpha = 0.00001\")\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    "\n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "ntZxI1fGCP9P",
    "outputId": "3f5d5f48-8fff-4e59-cc91-7aa4aab07951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 0.001\n",
      "Accuracy : 0.1937\n",
      "Hamming loss  0.0031152\n",
      "Micro-average quality numbers\n",
      "Precision: 0.6039, Recall: 0.3019, F1-measure: 0.4025\n",
      "Macro-average quality numbers\n",
      "Precision: 0.4175, Recall: 0.2321, F1-measure: 0.2794\n",
      "For alpha = 0.1\n",
      "Accuracy : 0.12911\n",
      "Hamming loss  0.00343118\n",
      "Micro-average quality numbers\n",
      "Precision: 0.9291, Recall: 0.0140, F1-measure: 0.0276\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0019, Recall: 0.0009, F1-measure: 0.0012\n",
      "For alpha = 1\n",
      "Accuracy : 0.12065\n",
      "Hamming loss  0.00347624\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "Time taken to run this cell : 2:01:02.817008\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "log_classifiers = {0.00001: classifier}\n",
    "alphas = [0.001, 0.1, 1]\n",
    "for alpha in alphas: \n",
    "  classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=alpha, penalty='l1'))\n",
    "  classifier.fit(x_train_multilabel, y_train)\n",
    "  predictions = classifier.predict(x_test_multilabel)\n",
    "\n",
    "  print(\"For alpha = {}\".format(alpha))\n",
    "  print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "  print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "  precision = precision_score(y_test, predictions, average='micro')\n",
    "  recall = recall_score(y_test, predictions, average='micro')\n",
    "  f1 = f1_score(y_test, predictions, average='micro')\n",
    "  \n",
    "  print(\"Micro-average quality numbers\")\n",
    "  print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "  precision = precision_score(y_test, predictions, average='macro')\n",
    "  recall = recall_score(y_test, predictions, average='macro')\n",
    "  f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "  print(\"Macro-average quality numbers\")\n",
    "  print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "  log_classifiers[alpha] = classifier\n",
    "  \n",
    "\n",
    "#   print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eWLrGJOJAppP",
    "outputId": "e5a70c62-e0fa-4356-f07c-55bff44d14be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-05: OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal', loss='log',\n",
       "                                             max_iter=1000, n_iter_no_change=5,\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             power_t=0.5, random_state=None,\n",
       "                                             shuffle=True, tol=0.001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                     n_jobs=None),\n",
       " 0.001: OneVsRestClassifier(estimator=SGDClassifier(alpha=0.001, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal', loss='log',\n",
       "                                             max_iter=1000, n_iter_no_change=5,\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             power_t=0.5, random_state=None,\n",
       "                                             shuffle=True, tol=0.001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                     n_jobs=None),\n",
       " 0.1: OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal', loss='log',\n",
       "                                             max_iter=1000, n_iter_no_change=5,\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             power_t=0.5, random_state=None,\n",
       "                                             shuffle=True, tol=0.001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                     n_jobs=None),\n",
       " 1: OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal', loss='log',\n",
       "                                             max_iter=1000, n_iter_no_change=5,\n",
       "                                             n_jobs=None, penalty='l1',\n",
       "                                             power_t=0.5, random_state=None,\n",
       "                                             shuffle=True, tol=0.001,\n",
       "                                             validation_fraction=0.1, verbose=0,\n",
       "                                             warm_start=False),\n",
       "                     n_jobs=None)}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Applying Linear SVM with OneVsRest Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "tX_UzNIlA2Yb",
    "outputId": "1e197718-1b68-4cb5-86d1-c04ee396f3ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 1e-05\n",
      "Accuracy : 0.099\n",
      "Hamming loss  0.00574442\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2945, Recall: 0.4677, F1-measure: 0.3614\n",
      "Macro-average quality numbers\n",
      "Precision: 0.2089, Recall: 0.4089, F1-measure: 0.2682\n",
      "For alpha = 0.001\n",
      "Accuracy : 0.19105\n",
      "Hamming loss  0.00314352\n",
      "Micro-average quality numbers\n",
      "Precision: 0.5967, Recall: 0.2954, F1-measure: 0.3952\n",
      "Macro-average quality numbers\n",
      "Precision: 0.3265, Recall: 0.2276, F1-measure: 0.2519\n",
      "For alpha = 0.1\n",
      "Accuracy : 0.12975\n",
      "Hamming loss  0.00342498\n",
      "Micro-average quality numbers\n",
      "Precision: 0.8213, Recall: 0.0188, F1-measure: 0.0369\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0043, Recall: 0.0013, F1-measure: 0.0020\n",
      "For alpha = 1\n",
      "Accuracy : 0.12065\n",
      "Hamming loss  0.00347624\n",
      "Micro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "Macro-average quality numbers\n",
      "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
      "Time taken to run this cell : 5:53:04.814878\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "hinge_classifiers = {}\n",
    "alphas = [0.00001, 0.001, 0.1, 1]\n",
    "for alpha in alphas: \n",
    "  classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=alpha, penalty='l1'))\n",
    "  classifier.fit(x_train_multilabel, y_train)\n",
    "  predictions = classifier.predict(x_test_multilabel)\n",
    "\n",
    "  print(\"For alpha = {}\".format(alpha))\n",
    "  print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "  print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "  precision = precision_score(y_test, predictions, average='micro')\n",
    "  recall = recall_score(y_test, predictions, average='micro')\n",
    "  f1 = f1_score(y_test, predictions, average='micro')\n",
    "  \n",
    "  print(\"Micro-average quality numbers\")\n",
    "  print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "  precision = precision_score(y_test, predictions, average='macro')\n",
    "  recall = recall_score(y_test, predictions, average='macro')\n",
    "  f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "  print(\"Macro-average quality numbers\")\n",
    "  print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "  hinge_classifiers[alpha] = classifier\n",
    "  \n",
    "\n",
    "#   print (metrics.classification_report(y_test, predictions))\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we see the perforamce at alpha = 1e-5 and 1e-3 is good for both models. We can train model at 1e-4 and see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "tENmhMjQnMtj",
    "outputId": "ce8b2f46-7ab0-424e-cd53-e635765bf3fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 0.0001\n",
      "Accuracy : 0.15549\n",
      "Hamming loss  0.00370748\n",
      "Micro-average quality numbers\n",
      "Precision: 0.4633, Recall: 0.4201, F1-measure: 0.4407\n",
      "Macro-average quality numbers\n",
      "Precision: 0.3563, Recall: 0.3642, F1-measure: 0.3474\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0001\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=alpha, penalty='l1'))\n",
    "classifier.fit(x_train_multilabel, y_train)\n",
    "predictions = classifier.predict(x_test_multilabel)\n",
    "\n",
    "print(\"For alpha = {}\".format(alpha))\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    "\n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "# log_classifiers[alpha] = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "ilE7DW7jnY9_",
    "outputId": "2bc7b3cb-62c1-481c-d834-3541884bc049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For alpha = 0.0001\n",
      "Accuracy : 0.15196\n",
      "Hamming loss  0.00372004\n",
      "Micro-average quality numbers\n",
      "Precision: 0.4613, Recall: 0.4177, F1-measure: 0.4384\n",
      "Macro-average quality numbers\n",
      "Precision: 0.3403, Recall: 0.3587, F1-measure: 0.3377\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.0001\n",
    "classifier = OneVsRestClassifier(SGDClassifier(loss='hinge', alpha=alpha, penalty='l1'))\n",
    "classifier.fit(x_train_multilabel, y_train)\n",
    "predictions = classifier.predict(x_test_multilabel)\n",
    "\n",
    "print(\"For alpha = {}\".format(alpha))\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test,predictions))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='micro')\n",
    "recall = recall_score(y_test, predictions, average='micro')\n",
    "f1 = f1_score(y_test, predictions, average='micro')\n",
    "\n",
    "print(\"Micro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='macro')\n",
    "recall = recall_score(y_test, predictions, average='macro')\n",
    "f1 = f1_score(y_test, predictions, average='macro')\n",
    "\n",
    "print(\"Macro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "hinge_classifiers[alpha] = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1122
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "08adrhSGZO36",
    "outputId": "187c61a3-4e80-48c5-b473-ad69dd396ce5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1e-05: OneVsRestClassifier(estimator=SGDClassifier(alpha=1e-05, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal',\n",
       "                                             loss='hinge', max_iter=1000,\n",
       "                                             n_iter_no_change=5, n_jobs=None,\n",
       "                                             penalty='l1', power_t=0.5,\n",
       "                                             random_state=None, shuffle=True,\n",
       "                                             tol=0.001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                     n_jobs=None),\n",
       " 0.0001: OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal',\n",
       "                                             loss='hinge', max_iter=1000,\n",
       "                                             n_iter_no_change=5, n_jobs=None,\n",
       "                                             penalty='l1', power_t=0.5,\n",
       "                                             random_state=None, shuffle=True,\n",
       "                                             tol=0.001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                     n_jobs=None),\n",
       " 0.001: OneVsRestClassifier(estimator=SGDClassifier(alpha=0.001, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal',\n",
       "                                             loss='hinge', max_iter=1000,\n",
       "                                             n_iter_no_change=5, n_jobs=None,\n",
       "                                             penalty='l1', power_t=0.5,\n",
       "                                             random_state=None, shuffle=True,\n",
       "                                             tol=0.001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                     n_jobs=None),\n",
       " 0.1: OneVsRestClassifier(estimator=SGDClassifier(alpha=0.1, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal',\n",
       "                                             loss='hinge', max_iter=1000,\n",
       "                                             n_iter_no_change=5, n_jobs=None,\n",
       "                                             penalty='l1', power_t=0.5,\n",
       "                                             random_state=None, shuffle=True,\n",
       "                                             tol=0.001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                     n_jobs=None),\n",
       " 1: OneVsRestClassifier(estimator=SGDClassifier(alpha=1, average=False,\n",
       "                                             class_weight=None,\n",
       "                                             early_stopping=False, epsilon=0.1,\n",
       "                                             eta0=0.0, fit_intercept=True,\n",
       "                                             l1_ratio=0.15,\n",
       "                                             learning_rate='optimal',\n",
       "                                             loss='hinge', max_iter=1000,\n",
       "                                             n_iter_no_change=5, n_jobs=None,\n",
       "                                             penalty='l1', power_t=0.5,\n",
       "                                             random_state=None, shuffle=True,\n",
       "                                             tol=0.001, validation_fraction=0.1,\n",
       "                                             verbose=0, warm_start=False),\n",
       "                     n_jobs=None)}"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see the performance at alpha = 1e-4 is better than other values. Printing all performance values here as they are not well printed in the above output cells. and also table is created at end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Linear Regression (SGDClassifier with log loss):**\n",
    "- <b>For alpha = 0.00001 <br/>\n",
    "Accuracy : 0.09716 <br/>\n",
    "Hamming loss  0.00580116 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.2911, Recall: 0.4660, F1-measure: 0.3583 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.2061, Recall: 0.4068, F1-measure: 0.2653</b>\n",
    "- <b>For alpha = 0.0001 <br/>\n",
    "Accuracy : 0.15549 <br/>\n",
    "Hamming loss  0.00370748 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.4633, Recall: 0.4201, F1-measure: 0.4407 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.3563, Recall: 0.3642, F1-measure: 0.3474 </b>\n",
    "- <b>For alpha = 0.001 <br/>\n",
    "Accuracy : 0.1937 <br/>\n",
    "Hamming loss  0.0031152 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.6039, Recall: 0.3019, F1-measure: 0.4025 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.4175, Recall: 0.2321, F1-measure: 0.2794 </b>\n",
    "- <b>For alpha = 0.1 <br/>\n",
    "Accuracy : 0.12911 <br/>\n",
    "Hamming loss  0.00343118 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.9291, Recall: 0.0140, F1-measure: 0.0276 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.0019, Recall: 0.0009, F1-measure: 0.0012</b>\n",
    "- <b>For alpha = 1 <br/>\n",
    "Accuracy : 0.12065 <br/>\n",
    "Hamming loss  0.00347624 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000\n",
    "Time taken to run this cell : 2:01:02.817008</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For Linear-SVM (SGDClassifier with hinge loss):**\n",
    "- <b>For alpha = 1e-05 <br/>\n",
    "Accuracy : 0.099 <br/>\n",
    "Hamming loss  0.00574442 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.2945, Recall: 0.4677, F1-measure: 0.3614 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.2089, Recall: 0.4089, F1-measure: 0.2682</b>\n",
    "- <b>For alpha = 0.0001 <br/>\n",
    "Accuracy : 0.15196 <br/>\n",
    "Hamming loss  0.00372004 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.4613, Recall: 0.4177, F1-measure: 0.4384 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.3403, Recall: 0.3587, F1-measure: 0.3377</b>\n",
    "- <b>For alpha = 0.001 <br/>\n",
    "Accuracy : 0.19105 <br/>\n",
    "Hamming loss  0.00314352 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.5967, Recall: 0.2954, F1-measure: 0.3952 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.3265, Recall: 0.2276, F1-measure: 0.2519</b>\n",
    "- <b>For alpha = 0.1 <br/>\n",
    "Accuracy : 0.12975 <br/>\n",
    "Hamming loss  0.00342498 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.8213, Recall: 0.0188, F1-measure: 0.0369 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.0043, Recall: 0.0013, F1-measure: 0.0020</b>\n",
    "- <b>For alpha = 1 <br/>\n",
    "Accuracy : 0.12065 <br/>\n",
    "Hamming loss  0.00347624 <br/>\n",
    "Micro-average quality numbers <br/>\n",
    "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000 <br/>\n",
    "Macro-average quality numbers <br/>\n",
    "Precision: 0.0000, Recall: 0.0000, F1-measure: 0.0000</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------------------+----------+----------+\n",
      "|        Model        | alpha (hyper-parameter) | micro-f1 | Accuracy |\n",
      "+---------------------+-------------------------+----------+----------+\n",
      "| Logistic Regression |          0.0001         |  0.4407  |  0.1555  |\n",
      "| Logistic Regression |          0.001          |  0.4025  |  0.1937  |\n",
      "|      Linear SVM     |          0.0001         |  0.4384  |  0.152   |\n",
      "|      Linear SVM     |          0.001          |  0.3952  |  0.191   |\n",
      "+---------------------+-------------------------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Model', 'alpha (hyper-parameter)', 'micro-f1', 'Accuracy']\n",
    "table.add_row(['Logistic Regression', 0.0001, 0.4407, 0.1555])\n",
    "table.add_row(['Logistic Regression', 0.001, 0.4025, 0.1937])\n",
    "table.add_row(['Linear SVM', 0.0001, 0.4384, 0.152])\n",
    "table.add_row(['Linear SVM', 0.001, 0.3952, 0.191])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here The micro f1 score is good for alpha = 0.0001 which is around 0.44 for both models. But the accuracy is good for alpha = 0.001 which is around 0.19 for both models. Bit more hyper-parameter tuning of alpha in range [0.0001, 0.001] might give better results but due to time and RAM issues not doing any other hyper-parameter tuning.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of SO_Tag_Predictor.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
