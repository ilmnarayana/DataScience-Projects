{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOP8G-jbxrkF"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import os\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "7nJiZcvXNY9d",
    "outputId": "da185c7d-d76c-4a03-aaef-1e741944df0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive/My Drive/AAIC/NetflixPrize\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My\\ Drive/AAIC/NetflixPrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YaQp6ArXUSte"
   },
   "outputs": [],
   "source": [
    "train_sparse_matrix = sparse.load_npz('train_sparse_matrix.npz')\n",
    "test_sparse_matrix = sparse.load_npz('test_sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rGuk8vtgaDev"
   },
   "source": [
    "### Some Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vLxdcStAZwMa"
   },
   "outputs": [],
   "source": [
    "def get_average_ratings(sparse_matrix, of_users):\n",
    "    \n",
    "    # average ratings of user/axes\n",
    "    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n",
    "\n",
    "    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n",
    "    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n",
    "    # Boolean matrix of ratings ( whether a user rated that movie or not)\n",
    "    is_rated = sparse_matrix!=0\n",
    "    # no of ratings that each user OR movie..\n",
    "    no_of_ratings = is_rated.sum(axis=ax).A1\n",
    "    \n",
    "    # max_user  and max_movie ids in sparse matrix \n",
    "    u,m = sparse_matrix.shape\n",
    "    # creae a dictonary of users and their average ratigns..\n",
    "    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n",
    "                                 for i in range(u if of_users else m) \n",
    "                                    if no_of_ratings[i] !=0}\n",
    "\n",
    "    # return that dictionary of average ratings\n",
    "    return average_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOmrWbsPaHiO"
   },
   "source": [
    "### Utility functions for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_BMFnxMxZ8Jb"
   },
   "outputs": [],
   "source": [
    "# to get rmse and mape given actual and predicted ratings..\n",
    "def get_error_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean([ (y_true[i] - y_pred[i])**2 for i in range(len(y_pred)) ]))\n",
    "    mape = np.mean(np.abs( (y_true - y_pred)/y_true )) * 100\n",
    "    return rmse, mape\n",
    "\n",
    "###################################################################\n",
    "###################################################################\n",
    "def run_xgboost(algo,  x_train, y_train, x_test, y_test, verbose=True):\n",
    "    \"\"\"\n",
    "    It will return train_results and test_results\n",
    "    \"\"\"\n",
    "    \n",
    "    # dictionaries for storing train and test results\n",
    "    train_results = dict()\n",
    "    test_results = dict()\n",
    "    \n",
    "    \n",
    "    # fit the model\n",
    "    print('Training the model..')\n",
    "    start =datetime.now()\n",
    "    algo.fit(x_train, y_train, eval_metric = 'rmse')\n",
    "    print('Done. Time taken : {}\\n'.format(datetime.now()-start))\n",
    "    print('Done \\n')\n",
    "\n",
    "    # from the trained model, get the predictions....\n",
    "    print('Evaluating the model with TRAIN data...')\n",
    "    start =datetime.now()\n",
    "    y_train_pred = algo.predict(x_train)\n",
    "    # get the rmse and mape of train data...\n",
    "    rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n",
    "    \n",
    "    # store the results in train_results dictionary..\n",
    "    train_results = {'rmse': rmse_train,\n",
    "                    'mape' : mape_train,\n",
    "                    'predictions' : y_train_pred}\n",
    "    \n",
    "    #######################################\n",
    "    # get the test data predictions and compute rmse and mape\n",
    "    print('Evaluating Test data')\n",
    "    y_test_pred = algo.predict(x_test) \n",
    "    rmse_test, mape_test = get_error_metrics(y_true=y_test.values, y_pred=y_test_pred)\n",
    "    # store them in our test results dictionary.\n",
    "    test_results = {'rmse': rmse_test,\n",
    "                    'mape' : mape_test,\n",
    "                    'predictions':y_test_pred}\n",
    "    if verbose:\n",
    "        print('\\nTEST DATA')\n",
    "        print('-'*30)\n",
    "        print('RMSE : ', rmse_test)\n",
    "        print('MAPE : ', mape_test)\n",
    "        \n",
    "    # return these train and test results...\n",
    "    return train_results, test_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ncx3HO3KaMnw"
   },
   "source": [
    "### Utility functions for Surpise library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQK7FSS8aA4c"
   },
   "outputs": [],
   "source": [
    "# it is just to makesure that all of our algorithms should produce same results\n",
    "# everytime they run...\n",
    "\n",
    "my_seed = 15\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "##########################################################\n",
    "# get  (actual_list , predicted_list) ratings given list \n",
    "# of predictions (prediction is a class in Surprise).    \n",
    "##########################################################\n",
    "def get_ratings(predictions):\n",
    "    actual = np.array([pred.r_ui for pred in predictions])\n",
    "    pred = np.array([pred.est for pred in predictions])\n",
    "    \n",
    "    return actual, pred\n",
    "\n",
    "################################################################\n",
    "# get ''rmse'' and ''mape'' , given list of prediction objecs \n",
    "################################################################\n",
    "def get_errors(predictions, print_them=False):\n",
    "\n",
    "    actual, pred = get_ratings(predictions)\n",
    "    rmse = np.sqrt(np.mean((pred - actual)**2))\n",
    "    mape = np.mean(np.abs(pred - actual)/actual)\n",
    "\n",
    "    return rmse, mape*100\n",
    "\n",
    "##################################################################################\n",
    "# It will return predicted ratings, rmse and mape of both train and test data   #\n",
    "##################################################################################\n",
    "def run_surprise(algo, trainset, testset, verbose=True): \n",
    "    '''\n",
    "        return train_dict, test_dict\n",
    "    \n",
    "        It returns two dictionaries, one for train and the other is for test\n",
    "        Each of them have 3 key-value pairs, which specify ''rmse'', ''mape'', and ''predicted ratings''.\n",
    "    '''\n",
    "    start = datetime.now()\n",
    "    # dictionaries that stores metrics for train and test..\n",
    "    train = dict()\n",
    "    test = dict()\n",
    "    \n",
    "    # train the algorithm with the trainset\n",
    "    st = datetime.now()\n",
    "    print('Training the model...')\n",
    "    algo.fit(trainset)\n",
    "    print('Done. time taken : {} \\n'.format(datetime.now()-st))\n",
    "    \n",
    "    # ---------------- Evaluating train data--------------------#\n",
    "    st = datetime.now()\n",
    "    print('Evaluating the model with train data..')\n",
    "    # get the train predictions (list of prediction class inside Surprise)\n",
    "    train_preds = algo.test(trainset.build_testset())\n",
    "    # get predicted ratings from the train predictions..\n",
    "    train_actual_ratings, train_pred_ratings = get_ratings(train_preds)\n",
    "    # get ''rmse'' and ''mape'' from the train predictions.\n",
    "    train_rmse, train_mape = get_errors(train_preds)\n",
    "    print('time taken : {}'.format(datetime.now()-st))\n",
    "    \n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Train Data')\n",
    "        print('-'*15)\n",
    "        print(\"RMSE : {}\\n\\nMAPE : {}\\n\".format(train_rmse, train_mape))\n",
    "    \n",
    "    #store them in the train dictionary\n",
    "    if verbose:\n",
    "        print('adding train results in the dictionary..')\n",
    "    train['rmse'] = train_rmse\n",
    "    train['mape'] = train_mape\n",
    "    train['predictions'] = train_pred_ratings\n",
    "    \n",
    "    #------------ Evaluating Test data---------------#\n",
    "    st = datetime.now()\n",
    "    print('\\nEvaluating for test data...')\n",
    "    # get the predictions( list of prediction classes) of test data\n",
    "    test_preds = algo.test(testset)\n",
    "    # get the predicted ratings from the list of predictions\n",
    "    test_actual_ratings, test_pred_ratings = get_ratings(test_preds)\n",
    "    # get error metrics from the predicted and actual ratings\n",
    "    test_rmse, test_mape = get_errors(test_preds)\n",
    "    print('time taken : {}'.format(datetime.now()-st))\n",
    "    \n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Test Data')\n",
    "        print('-'*15)\n",
    "        print(\"RMSE : {}\\n\\nMAPE : {}\\n\".format(test_rmse, test_mape))\n",
    "    # store them in test dictionary\n",
    "    if verbose:\n",
    "        print('storing the test results in test dictionary...')\n",
    "    test['rmse'] = test_rmse\n",
    "    test['mape'] = test_mape\n",
    "    test['predictions'] = test_pred_ratings\n",
    "    \n",
    "    print('\\n'+'-'*45)\n",
    "    print('Total time taken to run this algorithm :', datetime.now() - start)\n",
    "    \n",
    "    # return two dictionaries train and test\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKFfQ0bgxrqF"
   },
   "source": [
    "<h2> Sampling Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBOQj4nmxrqD"
   },
   "outputs": [],
   "source": [
    "def get_sample_sparse_matrix(sparse_matrix, no_users, no_movies, path, verbose = True):\n",
    "    \"\"\"\n",
    "        It will get it from the ''path'' if it is present  or It will create \n",
    "        and store the sampled sparse matrix in the path specified.\n",
    "    \"\"\"\n",
    "\n",
    "    # get (row, col) and (rating) tuple from sparse_matrix...\n",
    "    row_ind, col_ind, ratings = sparse.find(sparse_matrix)\n",
    "    users = np.unique(row_ind)\n",
    "    movies = np.unique(col_ind)\n",
    "\n",
    "    print(\"Original Matrix : (users, movies) -- ({} {})\".format(len(users), len(movies)))\n",
    "    print(\"Original Matrix : Ratings -- {}\\n\".format(len(ratings)))\n",
    "\n",
    "    # It just to make sure to get same sample everytime we run this program..\n",
    "    # and pick without replacement....\n",
    "    np.random.seed(15)\n",
    "    sample_users = np.random.choice(users, no_users, replace=False)\n",
    "    sample_movies = np.random.choice(movies, no_movies, replace=False)\n",
    "    # get the boolean mask or these sampled_items in originl row/col_inds..\n",
    "    mask = np.logical_and( np.isin(row_ind, sample_users),\n",
    "                      np.isin(col_ind, sample_movies) )\n",
    "    \n",
    "    sample_sparse_matrix = sparse.csr_matrix((ratings[mask], (row_ind[mask], col_ind[mask])),\n",
    "                                             shape=(max(sample_users)+1, max(sample_movies)+1))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Sampled Matrix : (users, movies) -- ({} {})\".format(len(sample_users), len(sample_movies)))\n",
    "        print(\"Sampled Matrix : Ratings --\", format(ratings[mask].shape[0]))\n",
    "\n",
    "    print('Saving it into disk for furthur usage..')\n",
    "    # save it into disk\n",
    "    sparse.save_npz(path, sample_sparse_matrix)\n",
    "    if verbose:\n",
    "            print('Done..\\n')\n",
    "    \n",
    "    return sample_sparse_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Av5WS6n2xrsZ"
   },
   "source": [
    "<h1> 5. Assignment </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "JkK0HIzgxrsd"
   },
   "source": [
    "1.Instead of using 10K users and 1K movies to train the above models, use 25K users and 3K movies (or more) to train all of the above models. Report the RMSE and MAPE on the test data using larger amount of data and provide a comparison between various models as shown above.\n",
    "\n",
    "NOTE: Please be patient as some of the code snippets make take many hours to compelte execution.\n",
    "\n",
    "2.Tune hyperparamters of all the Xgboost models above to improve the RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jLFR-p1xrqG"
   },
   "source": [
    "### Building sample data sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9LIyGtgvUrnm"
   },
   "source": [
    "**I will take train sample size of (25K, 2.5K) and test sample size of (12.5K, 1.25K)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "l5dJ4yzVxrqH",
    "outputId": "a8a60ee0-d3f7-4110-c82c-6777fed87fa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix : (users, movies) -- (405041 17424)\n",
      "Original Matrix : Ratings -- 80384405\n",
      "\n",
      "Sampled Matrix : (users, movies) -- (25000 2500)\n",
      "Sampled Matrix : Ratings -- 728487\n",
      "Saving it into disk for furthur usage..\n",
      "Done..\n",
      "\n",
      "Original Matrix : (users, movies) -- (349312 17757)\n",
      "Original Matrix : Ratings -- 20096102\n",
      "\n",
      "Sampled Matrix : (users, movies) -- (12500 1250)\n",
      "Sampled Matrix : Ratings -- 58236\n",
      "Saving it into disk for furthur usage..\n",
      "Done..\n",
      "\n",
      "0:01:11.993314\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "sample_train_sparse_matrix = get_sample_sparse_matrix(train_sparse_matrix, no_users=25000, no_movies=2500,\n",
    "                                             path = \"sample_train_sparse_matrix.npz\")\n",
    "sample_test_sparse_matrix = get_sample_sparse_matrix(test_sparse_matrix, no_users=12500, no_movies=1250,\n",
    "                                                 path = \"sample_test_sparse_matrix.npz\")\n",
    "print(datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhKqG4ZsMzA1"
   },
   "outputs": [],
   "source": [
    "sample_train_sparse_matrix = sparse.load_npz('sample_train_sparse_matrix.npz')\n",
    "sample_test_sparse_matrix = sparse.load_npz('sample_test_sparse_matrix.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fv0ISIdZY___"
   },
   "source": [
    "### Finding Global Average of all movie ratings, Average rating per User, and Average rating per Movie (from sampled train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RCfYRdQY_zX"
   },
   "outputs": [],
   "source": [
    "sample_train_averages = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eJN92jujxrqQ",
    "outputId": "821b4f95-4b2f-4b01-e98e-52c1f5e9d1d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global': 3.5816905449239314}"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_average = sample_train_sparse_matrix.sum()/sample_train_sparse_matrix.count_nonzero()\n",
    "sample_train_averages['global'] = global_average\n",
    "sample_train_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "iLBPu2ObxrqT",
    "outputId": "3f192da3-c49e-4073-f087-7adc594530d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average rating of user 1515220 : 3.9464285714285716\n"
     ]
    }
   ],
   "source": [
    "sample_train_averages['user'] = get_average_ratings(sample_train_sparse_matrix, of_users=True)\n",
    "print('\\nAverage rating of user 1515220 :',sample_train_averages['user'][1515220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "q8QD09k4xrqV",
    "outputId": "e683e572-3806-458c-e1ba-3c6bf0e44ade",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " AVerage rating of movie 15153 : 2.752\n"
     ]
    }
   ],
   "source": [
    "sample_train_averages['movie'] =  get_average_ratings(sample_train_sparse_matrix, of_users=False)\n",
    "print('\\n AVerage rating of movie 15153 :',sample_train_averages['movie'][15153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "E85auQgixrqZ",
    "outputId": "91cced86-56e7-49af-ade1-43c6fa5271cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " No of ratings in Our Sampled train matrix is : 728487\n",
      "\n",
      "\n",
      " No of ratings in Our Sampled test  matrix is : 58236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n No of ratings in Our Sampled train matrix is : {}\\n'.format(sample_train_sparse_matrix.count_nonzero()))\n",
    "print('\\n No of ratings in Our Sampled test  matrix is : {}\\n'.format(sample_test_sparse_matrix.count_nonzero()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ7FYSibxrqc"
   },
   "source": [
    "<h3>Featurizing data for regression problem </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZMRQApaxrqc"
   },
   "source": [
    "<h4>Featurizing train data </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMTXqVR3xrqd"
   },
   "outputs": [],
   "source": [
    "# get users, movies and ratings from our samples train sparse matrix\n",
    "sample_train_users, sample_train_movies, sample_train_ratings = sparse.find(sample_train_sparse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SZBPAij58B5"
   },
   "source": [
    "**Trying to reduce the computation time by pre calculating the row numbers and column numbers in which ratings are not zero. So `movie_seen_users` is dictionary where key is movie number and value for a particular movie is list of user ids who saw that movie. similarly `user_seen_movies` is dictionary for list of movies a user saw.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6tTP9arUzVlI",
    "outputId": "8ba4f0b5-22d3-49f2-ed61-90a038d79ac0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2464/2464 [00:57<00:00, 43.19it/s]\n",
      "100%|██████████| 23841/23841 [00:06<00:00, 3672.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "movie_seen_users = {}\n",
    "for mov in tqdm(set(sample_train_movies)):\n",
    "  row_inds = sample_train_sparse_matrix[:, mov]>0\n",
    "  movie_seen_users[mov] = row_inds.nonzero()[0]\n",
    "\n",
    "user_seen_movies = {}\n",
    "for user in tqdm(set(sample_train_users)):\n",
    "  col_inds = sample_train_sparse_matrix[user, :]>0\n",
    "  user_seen_movies[user] = col_inds.nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "O2lPhXj-ESu-",
    "outputId": "7ed02065-522f-48b6-b602-92094bb1a076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   10,   836,  3046,  3863,  3875,  3952,  4633,  5402,  5515,\n",
       "        5516,  5614,  5940,  7355,  7795,  7904,  8904,  8960,  9983,\n",
       "       11153, 11442, 12034, 12293, 13254, 13413, 13614, 16865, 17157,\n",
       "       17381, 17387], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_seen_movies[sample_train_users[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GSP39M-V9EN"
   },
   "source": [
    "**Testing if our previous code (present in original notebook) and new optimized code gives same output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "vaTUNG1-i-uQ",
    "outputId": "148cf0ee-d3c7-4d51-d096-2bc483c8b2cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 4, 5, 4]\n",
      "time: 0:00:00.195081\n",
      "[5, 4, 4, 5, 4]\n",
      "time: 0:00:00.007723\n"
     ]
    }
   ],
   "source": [
    "(user, movie, rating) = (sample_train_users[0], sample_train_movies[0], sample_train_ratings[0])\n",
    "\n",
    "start = datetime.now()\n",
    "user_sim = cosine_similarity(sample_train_sparse_matrix[user], sample_train_sparse_matrix).ravel()\n",
    "top_sim_users = user_sim.argsort()[::-1][1:]\n",
    "top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "print(top_sim_users_ratings)\n",
    "print('time: '+str(datetime.now()-start))\n",
    "\n",
    "start = datetime.now()\n",
    "movie_seen_inds = movie_seen_users[movie]\n",
    "movie_seen_matrix = sample_train_sparse_matrix[movie_seen_inds]\n",
    "user_sim = cosine_similarity(sample_train_sparse_matrix[user], movie_seen_matrix).ravel()\n",
    "top_sim_users = movie_seen_inds[user_sim.argsort()[::-1][1:]]\n",
    "top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "top_sim_users_ratings = list(top_ratings[:5])\n",
    "top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "print(top_sim_users_ratings)\n",
    "print('time: '+str(datetime.now()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SHfDjBtfWNHN"
   },
   "source": [
    "**Above teseted for only 1 row. Now I am testing for top 100 rows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "UqbdqSYC_JGF",
    "outputId": "5b731145-1077-4486-eddb-f458704bfde5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:18.614557\n",
      "198169 17 2 [2, 2, 4, 5, 2] [2, 2, 4, 5, 5]\n",
      "587809 17 5 [3, 5, 2, 4, 4] [3, 2, 5, 4, 4]\n",
      "1302772 17 4 [3, 2, 5, 3, 3] [3, 5, 2, 3, 3]\n",
      "0:00:00.613557\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "res1 = []\n",
    "\n",
    "start = datetime.now()\n",
    "for i in range(100):\n",
    "  (user, movie, rating) = (sample_train_users[i], sample_train_movies[i], sample_train_ratings[i])\n",
    "\n",
    "  user_sim = cosine_similarity(sample_train_sparse_matrix[user], sample_train_sparse_matrix).ravel()\n",
    "  top_sim_users = user_sim.argsort()[::-1][1:]\n",
    "  top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "  top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "  top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "  res1.append(top_sim_users_ratings)\n",
    "print(datetime.now() - start)\n",
    "\n",
    "res2 = []\n",
    "\n",
    "start = datetime.now()\n",
    "for i in range(100):\n",
    "  (user, movie, rating) = (sample_train_users[i], sample_train_movies[i], sample_train_ratings[i])\n",
    "\n",
    "  movie_seen_inds = movie_seen_users[movie]\n",
    "  movie_seen_matrix = sample_train_sparse_matrix[movie_seen_inds]\n",
    "  user_sim = cosine_similarity(sample_train_sparse_matrix[user], movie_seen_matrix).ravel()\n",
    "  top_sim_users = movie_seen_inds[user_sim.argsort()[::-1][1:]]\n",
    "  top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "  top_sim_users_ratings = list(top_ratings[:5])\n",
    "  top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "  res2.append(top_sim_users_ratings)\n",
    "  if top_sim_users_ratings != res1[i]:\n",
    "    print(user, movie, rating, res1[i], top_sim_users_ratings)\n",
    "print(datetime.now() - start)\n",
    "\n",
    "print(res1 == res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRz_6sGQWcrW"
   },
   "source": [
    "**Time of execution reduced a lot (18 sec to 0.6 sec for 100 rows). But above 3 rows out of first 100 rows are printed which have different outputs from the original code. The output is in format of `user_id movie_id rating old_code_sim_user_ratings new_code_sim_user_ratings`.</br><br>The values seem to be swapped for some indices. So after debugging into those answers particularly I saw that the similar users for which the ratings are swapped have exact similarity. And while sorting they are in different positions in each code. As argsort uses quick sort it is difficult to swap them to particular order. So leaving as it is because the new output is also correct. to understand better I will write code below for one row.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "HD_OsRWw6QNa",
    "outputId": "45b45c82-1178-4917-9c27-20a1587ed960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0.43053851 0.41039134 0.41039134 0.32363804 0.29948618 0.28906354\n",
      " 0.28795192 0.28575985 0.2825669  0.28245069 0.27658523 0.26401849\n",
      " 0.25516567 0.25257841 0.23890732 0.23693955 0.23240006 0.23083335\n",
      " 0.23000323 0.22523151 0.21080044 0.20834464 0.20677584 0.20064082\n",
      " 0.20029971 0.19335076 0.19312534 0.19213069 0.18935687 0.18885347\n",
      " 0.18828706 0.17508463 0.1744335  0.1737617  0.17146746 0.16957244\n",
      " 0.16174824 0.15511335 0.15501086 0.15325634 0.15291064 0.15241552\n",
      " 0.15239901 0.15017085 0.14951632 0.14682607 0.14682607 0.14363697\n",
      " 0.14154557 0.14073721 0.14054218 0.1403425  0.14007809 0.1386829\n",
      " 0.1385179  0.13841282 0.13767326 0.13677339 0.13400692 0.13313641\n",
      " 0.13273005 0.13143042 0.12750623 0.12658802 0.12210612 0.12188001\n",
      " 0.12071602 0.12069029 0.12036541 0.11901052 0.11782568 0.11780766\n",
      " 0.11738784 0.11685787 0.1163395  0.11333876 0.11238658 0.11067431\n",
      " 0.10880673 0.10472928 0.10351164 0.10344904 0.10331783 0.10259784\n",
      " 0.10224344 0.1000487  0.09935206 0.0992612  0.09876681 0.09792861\n",
      " 0.09653175 0.09600559 0.09556853 0.09546538 0.09505506 0.09498714\n",
      " 0.09498714 0.09305542 0.09177888 0.09077877 0.0903652  0.08983416\n",
      " 0.08931875 0.08902638 0.08692252 0.08650132 0.08207827 0.08187474\n",
      " 0.07637253 0.07591744 0.07483453 0.07220372 0.06925895 0.06844107\n",
      " 0.06808408 0.06798669 0.06700267 0.06655265 0.06601894 0.06513697\n",
      " 0.06449007 0.06400569 0.06340869 0.06324116 0.06313713 0.06307496\n",
      " 0.06167015 0.0614819  0.06147711 0.0610083  0.0609522  0.06076631\n",
      " 0.05935868 0.05896677 0.05746628 0.05746628 0.05560604 0.05399055\n",
      " 0.05129892 0.05028762 0.049859   0.04920761 0.04730432 0.04690399\n",
      " 0.04512248 0.04325905 0.04083546 0.03648824 0.03477768 0.03413268\n",
      " 0.03113401 0.03067409 0.02760591 0.02704571 0.02315972 0.02247806\n",
      " 0.02044305 0.01461032]\n"
     ]
    }
   ],
   "source": [
    "inds = movie_seen_users[17]\n",
    "user_sim = cosine_similarity(sample_train_sparse_matrix[1302772], sample_train_sparse_matrix[inds]).ravel()\n",
    "user_sim_sort = user_sim[user_sim.argsort()[::-1][1:]]\n",
    "print(user_sim_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AMglWJmYjGc"
   },
   "source": [
    "**In above code you can see similarities of second and third user are exactly same so they are different order in old code and new code. Same happened for other rows as well. And for the row 198169 17, 5th and 6th users are swapped due to same similarity scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63dn5TMg_56e"
   },
   "source": [
    "**The results for top_sim_users_ratings are same. And we can see the time also reduced a lot. Now let us test for top_sim_movies_ratings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "oNBWnLwU_5R_",
    "outputId": "d304ec1d-aaa1-49a2-9536-3f001c3f1552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:30.999171\n",
      "0:00:15.610036\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "res1 = []\n",
    "\n",
    "start = datetime.now()\n",
    "for i in range(300):\n",
    "  (user, movie, rating) = (sample_train_users[i], sample_train_movies[i], sample_train_ratings[i])\n",
    "\n",
    "  movie_sim = cosine_similarity(sample_train_sparse_matrix[:,movie].T, sample_train_sparse_matrix.T).ravel()\n",
    "  top_sim_movies = movie_sim.argsort()[::-1][1:]\n",
    "  top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "  top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "  top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n",
    "  res1.append(top_sim_movies_ratings)\n",
    "print(datetime.now() - start)\n",
    "\n",
    "res2 = []\n",
    "\n",
    "start = datetime.now()\n",
    "for i in range(300):\n",
    "  (user, movie, rating) = (sample_train_users[i], sample_train_movies[i], sample_train_ratings[i])\n",
    "\n",
    "  movie_inds = user_seen_movies[user]\n",
    "  user_seen_matrix = sample_train_sparse_matrix[:, movie_inds]\n",
    "  movie_sim = cosine_similarity(sample_train_sparse_matrix[:, movie].T, user_seen_matrix.T).ravel()\n",
    "  top_sim_movies = movie_inds[movie_sim.argsort()[::-1][1:]]\n",
    "  top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "  top_sim_movies_ratings = list(top_ratings[:5])\n",
    "  top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5 - len(top_sim_movies_ratings)))\n",
    "  res2.append(top_sim_movies_ratings)\n",
    "  if top_sim_movies_ratings != res1[i]:\n",
    "    print(user, movie, rating, res1[i], top_sim_movies_ratings)\n",
    "print(datetime.now() - start)\n",
    "\n",
    "\n",
    "print(res1 == res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUSRRnQaZRZi"
   },
   "source": [
    "**top_sim_movie_ratings gave same output for first 300 rows there is no difference between old and new code's outputs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkkYcjqyFplH"
   },
   "source": [
    "**So, now we replace our old code with new optimized code. In above results we can see time only reduced around half for calculating `top_sim_movies_ratings` and for calculating `top_sim_user_ratings` it reduced a lot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "Hr_gXr0ixrqh",
    "outputId": "26899eed-e3ae-4011-d992-ba575e924e74",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing 728487 tuples for the dataset..\n",
      "\n",
      "Done for 10000 rows----- 0:25:52.174264\n",
      "Done for 20000 rows----- 0:50:09.245747\n",
      "Done for 30000 rows----- 1:15:26.200129\n",
      "Done for 40000 rows----- 1:40:33.797394\n",
      "Done for 50000 rows----- 2:01:31.906810\n",
      "Done for 60000 rows----- 2:25:03.046298\n",
      "Done for 70000 rows----- 2:49:26.850206\n",
      "Done for 80000 rows----- 3:12:48.047996\n",
      "Done for 90000 rows----- 3:44:20.892994\n",
      "Done for 100000 rows----- 4:11:59.340568\n",
      "Done for 110000 rows----- 4:38:25.917317\n",
      "Done for 120000 rows----- 5:06:29.860894\n",
      "Done for 130000 rows----- 5:31:08.470382\n",
      "Done for 140000 rows----- 6:00:24.516043\n",
      "Done for 150000 rows----- 6:28:46.477878\n",
      "Done for 160000 rows----- 6:56:58.869733\n",
      "Done for 170000 rows----- 7:33:50.671702\n",
      "Done for 180000 rows----- 8:33:01.905846\n",
      "Done for 190000 rows----- 9:32:23.991411\n",
      "Done for 200000 rows----- 9:56:08.202252\n",
      "Done for 210000 rows----- 10:14:32.930756\n",
      "Done for 220000 rows----- 10:33:52.570624\n",
      "Done for 230000 rows----- 10:54:10.983074\n",
      "Done for 240000 rows----- 11:14:53.341763\n",
      "Done for 250000 rows----- 11:33:27.430486\n",
      "Done for 260000 rows----- 11:53:48.303065\n",
      "Done for 270000 rows----- 12:12:32.312815\n",
      "Done for 280000 rows----- 12:31:14.097855\n",
      "Done for 290000 rows----- 12:50:15.504039\n",
      "Done for 300000 rows----- 13:08:46.825215\n",
      "Done for 310000 rows----- 13:27:04.454216\n",
      "Done for 320000 rows----- 13:45:42.467673\n",
      "Done for 330000 rows----- 14:03:42.286014\n",
      "Done for 340000 rows----- 14:22:55.317302\n",
      "Done for 350000 rows----- 14:43:30.444403\n",
      "Done for 360000 rows----- 15:02:59.322528\n",
      "Done for 370000 rows----- 15:21:40.799859\n",
      "Done for 380000 rows----- 15:39:56.532963\n",
      "Done for 390000 rows----- 15:59:17.406681\n",
      "Done for 400000 rows----- 16:16:53.541318\n",
      "Done for 410000 rows----- 16:33:54.912055\n",
      "Done for 420000 rows----- 16:51:36.799703\n",
      "Done for 430000 rows----- 17:11:06.279531\n",
      "Done for 440000 rows----- 17:29:19.984800\n",
      "Done for 450000 rows----- 17:49:05.868462\n",
      "Done for 460000 rows----- 18:08:45.859237\n",
      "Done for 470000 rows----- 18:28:59.785504\n",
      "Done for 480000 rows----- 18:48:33.645824\n",
      "Done for 490000 rows----- 19:06:16.908563\n",
      "Done for 500000 rows----- 19:27:50.017406\n",
      "Done for 510000 rows----- 19:45:28.944638\n",
      "Done for 520000 rows----- 20:05:11.727781\n",
      "Done for 530000 rows----- 20:23:18.788863\n",
      "Done for 540000 rows----- 20:40:56.447844\n",
      "Done for 550000 rows----- 21:03:15.981074\n",
      "Done for 560000 rows----- 21:24:50.055391\n",
      "Done for 570000 rows----- 21:44:38.477295\n",
      "Done for 580000 rows----- 22:07:00.710925\n",
      "Done for 590000 rows----- 22:27:43.999495\n",
      "Done for 600000 rows----- 22:47:31.809832\n",
      "Done for 610000 rows----- 23:09:43.618458\n",
      "Done for 620000 rows----- 23:28:47.799743\n",
      "Done for 630000 rows----- 23:48:05.413334\n",
      "Done for 640000 rows----- 1 day, 0:06:24.883337\n",
      "Done for 650000 rows----- 1 day, 0:26:09.471442\n",
      "Done for 660000 rows----- 1 day, 0:45:10.640469\n",
      "Done for 670000 rows----- 1 day, 1:02:48.259453\n",
      "Done for 680000 rows----- 1 day, 1:21:00.082800\n",
      "Done for 690000 rows----- 1 day, 1:39:54.990425\n",
      "Done for 700000 rows----- 1 day, 2:02:13.709112\n",
      "Done for 710000 rows----- 1 day, 2:21:21.317444\n",
      "Done for 720000 rows----- 1 day, 2:39:30.094542\n",
      "1 day, 2:54:56.665223\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# It took me almost 27 hours to prepare this train dataset.#\n",
    "############################################################\n",
    "start = datetime.now()\n",
    "if os.path.isfile('reg_train.csv'):\n",
    "    print(\"File already exists you don't have to prepare again...\" )\n",
    "else:\n",
    "    print('preparing {} tuples for the dataset..\\n'.format(len(sample_train_ratings)))\n",
    "    with open('reg_train.csv', mode='w') as reg_data_file:\n",
    "        count = 0\n",
    "        for (user, movie, rating)  in zip(sample_train_users, sample_train_movies, sample_train_ratings):\n",
    "            st = datetime.now()\n",
    "            movie_seen_inds = movie_seen_users[movie]\n",
    "            movie_seen_matrix = sample_train_sparse_matrix[movie_seen_inds]\n",
    "            user_sim = cosine_similarity(sample_train_sparse_matrix[user], movie_seen_matrix).ravel()\n",
    "            top_sim_users = movie_seen_inds[user_sim.argsort()[::-1][1:]]\n",
    "            top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "            top_sim_users_ratings = list(top_ratings[:5])\n",
    "            top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "\n",
    "\n",
    "            movie_inds = user_seen_movies[user]\n",
    "            user_seen_matrix = sample_train_sparse_matrix[:, movie_inds]\n",
    "            movie_sim = cosine_similarity(sample_train_sparse_matrix[:, movie].T, user_seen_matrix.T).ravel()\n",
    "            top_sim_movies = movie_inds[movie_sim.argsort()[::-1][1:]]\n",
    "            top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "            top_sim_movies_ratings = list(top_ratings[:5])\n",
    "            top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5 - len(top_sim_movies_ratings)))\n",
    "\n",
    "            #-----------------prepare the row to be stores in a file-----------------#\n",
    "            row = list()\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            # Now add the other features to this data...\n",
    "            row.append(sample_train_averages['global']) # first feature\n",
    "            # next 5 features are similar_users \"movie\" ratings\n",
    "            row.extend(top_sim_users_ratings)\n",
    "            # next 5 features are \"user\" ratings for similar_movies\n",
    "            row.extend(top_sim_movies_ratings)\n",
    "            # Avg_user rating\n",
    "            row.append(sample_train_averages['user'][user])\n",
    "            # Avg_movie rating\n",
    "            row.append(sample_train_averages['movie'][movie])\n",
    "\n",
    "            # finalley, The actual Rating of this user-movie pair...\n",
    "            row.append(rating)\n",
    "            count = count + 1\n",
    "\n",
    "            # add rows to the file opened..\n",
    "            reg_data_file.write(','.join(map(str, row)))\n",
    "            reg_data_file.write('\\n')\n",
    "            if (count)%10000 == 0:\n",
    "                # print(','.join(map(str, row)))\n",
    "                print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))\n",
    "\n",
    "\n",
    "print(datetime.now() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3xJ8aWyxrqj"
   },
   "source": [
    "__Reading from the file to make a Train_dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "oUs6s6AZxrqj",
    "outputId": "9635fb63-3453-45a7-9e20-c29d1c412994"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174683</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.793103</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233949</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.696970</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>555770</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.825000</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767518</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.789474</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>894393</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  movie      GAvg  sur1  sur2  ...  smr4  smr5      UAvg      MAvg  rating\n",
       "0  174683     10  3.581691   5.0   4.0  ...   2.0   4.0  3.793103  3.611111       5\n",
       "1  233949     10  3.581691   4.0   4.0  ...   3.0   3.0  2.696970  3.611111       3\n",
       "2  555770     10  3.581691   4.0   5.0  ...   4.0   4.0  3.825000  3.611111       4\n",
       "3  767518     10  3.581691   5.0   2.0  ...   3.0   3.0  3.789474  3.611111       5\n",
       "4  894393     10  3.581691   3.0   4.0  ...   4.0   4.0  4.000000  3.611111       4\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_train = pd.read_csv('reg_train.csv', names = ['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5','smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating'], header=None)\n",
    "reg_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Ij3Oj6_UPOST",
    "outputId": "ab962881-651e-4d37-c552-c39df5f07565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728487, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e90d1zMCxrql"
   },
   "source": [
    "-----------------------\n",
    "\n",
    "- __GAvg__ : Average rating of all the ratings \n",
    "\n",
    "\n",
    "- __Similar users rating of this movie__:\n",
    "    - sur1, sur2, sur3, sur4, sur5 ( top 5 similar users who rated that movie.. )\n",
    "    \n",
    "\n",
    "\n",
    "- __Similar movies rated by this user__:\n",
    "    - smr1, smr2, smr3, smr4, smr5 ( top 5 similar movies rated by this movie.. )\n",
    "\n",
    "\n",
    "- __UAvg__ : User's Average rating\n",
    "\n",
    "\n",
    "- __MAvg__ : Average rating of this movie\n",
    "\n",
    "\n",
    "- __rating__ : Rating of this movie by this user.\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kW-WflXTxrqm"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9vMR-Edxrqm"
   },
   "source": [
    "<h4> 4.3.1.2 Featurizing test data </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M2QBhCcMxrqm"
   },
   "outputs": [],
   "source": [
    "# get users, movies and ratings from the Sampled Test \n",
    "sample_test_users, sample_test_movies, sample_test_ratings = sparse.find(sample_test_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nDL4-uKcxrqo",
    "outputId": "8ebf8ddf-7b29-4335-b267-8fed45dd36ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5816905449239314"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train_averages['global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CLVejZA3xrqs",
    "outputId": "2067460e-fcbf-428b-af55-6949d0e2b44a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing 58236 tuples for the dataset..\n",
      "\n",
      "Done for 1000 rows----- 0:00:02.039362\n",
      "Done for 2000 rows----- 0:00:21.470450\n",
      "Done for 3000 rows----- 0:00:23.971523\n",
      "Done for 4000 rows----- 0:00:26.583884\n",
      "Done for 5000 rows----- 0:00:28.780000\n",
      "Done for 6000 rows----- 0:00:30.474036\n",
      "Done for 7000 rows----- 0:00:33.142994\n",
      "Done for 8000 rows----- 0:00:35.398097\n",
      "Done for 9000 rows----- 0:00:44.862423\n",
      "Done for 10000 rows----- 0:00:47.401982\n",
      "Done for 11000 rows----- 0:00:49.810225\n",
      "Done for 12000 rows----- 0:00:52.407573\n",
      "Done for 13000 rows----- 0:00:53.991830\n",
      "Done for 14000 rows----- 0:00:56.102168\n",
      "Done for 15000 rows----- 0:01:07.592725\n",
      "Done for 16000 rows----- 0:01:16.419779\n",
      "Done for 17000 rows----- 0:01:39.229407\n",
      "Done for 18000 rows----- 0:01:42.609114\n",
      "Done for 19000 rows----- 0:01:52.742374\n",
      "Done for 20000 rows----- 0:02:04.371053\n",
      "Done for 21000 rows----- 0:02:05.906774\n",
      "Done for 22000 rows----- 0:02:15.817522\n",
      "Done for 23000 rows----- 0:02:27.061909\n",
      "Done for 24000 rows----- 0:02:28.621427\n",
      "Done for 25000 rows----- 0:02:30.956004\n",
      "Done for 26000 rows----- 0:02:35.297383\n",
      "Done for 27000 rows----- 0:02:37.872863\n",
      "Done for 28000 rows----- 0:02:41.768632\n",
      "Done for 29000 rows----- 0:02:43.629004\n",
      "Done for 30000 rows----- 0:02:44.404272\n",
      "Done for 31000 rows----- 0:02:46.365282\n",
      "Done for 32000 rows----- 0:02:48.789630\n",
      "Done for 33000 rows----- 0:02:50.237899\n",
      "Done for 34000 rows----- 0:02:54.981331\n",
      "Done for 35000 rows----- 0:02:58.056991\n",
      "Done for 36000 rows----- 0:02:59.965310\n",
      "Done for 37000 rows----- 0:03:10.617633\n",
      "Done for 38000 rows----- 0:03:25.772518\n",
      "Done for 39000 rows----- 0:03:27.875646\n",
      "Done for 40000 rows----- 0:03:30.350553\n",
      "Done for 41000 rows----- 0:03:32.930046\n",
      "Done for 42000 rows----- 0:03:43.206103\n",
      "Done for 43000 rows----- 0:03:44.811910\n",
      "Done for 44000 rows----- 0:03:49.498793\n",
      "Done for 45000 rows----- 0:03:59.146509\n",
      "Done for 46000 rows----- 0:04:01.131168\n",
      "Done for 47000 rows----- 0:04:05.165064\n",
      "Done for 48000 rows----- 0:04:12.789808\n",
      "Done for 49000 rows----- 0:04:27.029902\n",
      "Done for 50000 rows----- 0:04:28.359328\n",
      "Done for 51000 rows----- 0:04:29.453875\n",
      "Done for 52000 rows----- 0:04:32.713419\n",
      "Done for 53000 rows----- 0:04:35.204507\n",
      "Done for 54000 rows----- 0:04:37.611386\n",
      "Done for 55000 rows----- 0:04:39.621891\n",
      "Done for 56000 rows----- 0:04:41.769840\n",
      "Done for 57000 rows----- 0:04:43.936698\n",
      "Done for 58000 rows----- 0:04:46.575721\n",
      " 0:04:47.020557\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "if os.path.isfile('reg_test.csv'):\n",
    "    print(\"It is already created...\")\n",
    "else:\n",
    "\n",
    "    print('preparing {} tuples for the dataset..\\n'.format(len(sample_test_ratings)))\n",
    "    with open('reg_test.csv', mode='w') as reg_data_file:\n",
    "        count = 0 \n",
    "        for (user, movie, rating)  in zip(sample_test_users, sample_test_movies, sample_test_ratings):\n",
    "            st = datetime.now()\n",
    "            top_sim_users_ratings = []\n",
    "            top_sim_movies_ratings = []\n",
    "        #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n",
    "            #print(user, movie)\n",
    "            try:\n",
    "                movie_seen_inds = movie_seen_users[movie]\n",
    "                movie_seen_matrix = sample_train_sparse_matrix[movie_seen_inds]\n",
    "                user_sim = cosine_similarity(sample_train_sparse_matrix[user], movie_seen_matrix).ravel()\n",
    "                top_sim_users = movie_seen_inds[user_sim.argsort()[::-1][1:]]\n",
    "                top_ratings = sample_train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "                top_sim_users_ratings = list(top_ratings[:5])\n",
    "                top_sim_users_ratings.extend([sample_train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "\n",
    "            except (IndexError, KeyError):\n",
    "                # It is a new User or new Movie or there are no ratings for given user for top similar movies...\n",
    "                ########## Cold STart Problem ##########\n",
    "                top_sim_users_ratings.extend([sample_train_averages['global']]*(5 - len(top_sim_users_ratings)))\n",
    "                #print(top_sim_users_ratings)\n",
    "            except:\n",
    "                print(user, movie)\n",
    "                # we just want KeyErrors to be resolved. Not every Exception...\n",
    "                raise\n",
    "\n",
    "\n",
    "\n",
    "            #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n",
    "            try:\n",
    "                # compute the similar movies of the \"movie\"\n",
    "                movie_inds = user_seen_movies[user]\n",
    "                user_seen_matrix = sample_train_sparse_matrix[:, movie_inds]\n",
    "                movie_sim = cosine_similarity(sample_train_sparse_matrix[:, movie].T, user_seen_matrix.T).ravel()\n",
    "                top_sim_movies = movie_inds[movie_sim.argsort()[::-1][1:]]\n",
    "                top_ratings = sample_train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "                top_sim_movies_ratings = list(top_ratings[:5])\n",
    "                top_sim_movies_ratings.extend([sample_train_averages['user'][user]]*(5 - len(top_sim_movies_ratings)))\n",
    "                #print(top_sim_movies_ratings)\n",
    "            except (IndexError, KeyError):\n",
    "                #print(top_sim_movies_ratings, end=\" : -- \")\n",
    "                top_sim_movies_ratings.extend([sample_train_averages['global']]*(5-len(top_sim_movies_ratings)))\n",
    "                #print(top_sim_movies_ratings)\n",
    "            except :\n",
    "                raise\n",
    "\n",
    "            #-----------------prepare the row to be stores in a file-----------------#\n",
    "            row = list()\n",
    "            # add usser and movie name first\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            row.append(sample_train_averages['global']) # first feature\n",
    "            #print(row)\n",
    "            # next 5 features are similar_users \"movie\" ratings\n",
    "            row.extend(top_sim_users_ratings)\n",
    "            #print(row)\n",
    "            # next 5 features are \"user\" ratings for similar_movies\n",
    "            row.extend(top_sim_movies_ratings)\n",
    "            #print(row)\n",
    "            # Avg_user rating\n",
    "            try:\n",
    "                row.append(sample_train_averages['user'][user])\n",
    "            except KeyError:\n",
    "                row.append(sample_train_averages['global'])\n",
    "            except:\n",
    "                raise\n",
    "            #print(row)\n",
    "            # Avg_movie rating\n",
    "            try:\n",
    "                row.append(sample_train_averages['movie'][movie])\n",
    "            except KeyError:\n",
    "                row.append(sample_train_averages['global'])\n",
    "            except:\n",
    "                raise\n",
    "            #print(row)\n",
    "            # finalley, The actual Rating of this user-movie pair...\n",
    "            row.append(rating)\n",
    "            #print(row)\n",
    "            count = count + 1\n",
    "\n",
    "            # add rows to the file opened..\n",
    "            reg_data_file.write(','.join(map(str, row)))\n",
    "            #print(','.join(map(str, row)))\n",
    "            reg_data_file.write('\\n')        \n",
    "            if (count)%1000 == 0:\n",
    "                #print(','.join(map(str, row)))\n",
    "                print(\"Done for {} rows----- {}\".format(count, datetime.now() - start))\n",
    "    print(\"\",datetime.now() - start)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgiFyKukxrqu"
   },
   "source": [
    "__Reading from the file to make a test dataframe __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "id": "7mhv5Rztxrqv",
    "outputId": "09737eeb-a8db-4ab2-c8c3-2f3ff0109833"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1129620</td>\n",
       "      <td>2</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>779046</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>808635</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>898730</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  movie      GAvg      sur1  ...      smr5      UAvg      MAvg  rating\n",
       "0  1129620      2  3.581691  3.581691  ...  3.581691  3.581691  3.581691       3\n",
       "1   779046     71  3.581691  3.581691  ...  3.581691  3.581691  3.581691       5\n",
       "2   808635     71  3.581691  3.581691  ...  3.581691  3.581691  3.581691       5\n",
       "3   898730     71  3.581691  3.581691  ...  3.581691  3.581691  3.581691       3\n",
       "\n",
       "[4 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_test_df = pd.read_csv('reg_test.csv', names = ['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "                                                          'smr1', 'smr2', 'smr3', 'smr4', 'smr5',\n",
    "                                                          'UAvg', 'MAvg', 'rating'], header=None)\n",
    "reg_test_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "yXGQX0spPZuU",
    "outputId": "a7f1c86a-2706-46a7-9c50-8b1c2cadfece"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58236, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vWmzUruxrqx"
   },
   "source": [
    "-----------------------\n",
    "\n",
    "- __GAvg__ : Average rating of all the ratings \n",
    "\n",
    "\n",
    "- __Similar users rating of this movie__:\n",
    "    - sur1, sur2, sur3, sur4, sur5 ( top 5 simiular users who rated that movie.. )\n",
    "    \n",
    "\n",
    "\n",
    "- __Similar movies rated by this user__:\n",
    "    - smr1, smr2, smr3, smr4, smr5 ( top 5 simiular movies rated by this movie.. )\n",
    "\n",
    "\n",
    "- __UAvg__ : User AVerage rating\n",
    "\n",
    "\n",
    "- __MAvg__ : Average rating of this movie\n",
    "\n",
    "\n",
    "- __rating__ : Rating of this movie by this user.\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QM1iX_xyxrqx"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tLaiV_tZxrqy"
   },
   "source": [
    "<h3> 4.3.2 Transforming data for Surprise models</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "2d2vQJ5lxrqy",
    "outputId": "34fa4176-2fe7-40bc-8677-00ecac7e866b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
      "Collecting scikit-surprise (from surprise)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/da/b5700d96495fb4f092be497f02492768a3d96a3f4fa2ae7dea46d4081cfa/scikit-surprise-1.1.0.tar.gz (6.4MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5MB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.16.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.3.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.0-cp36-cp36m-linux_x86_64.whl size=1678068 sha256=b873c7162113e975e6dd27def3e307c36479e42ba23522bd03e1dbd3804859d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/cc/fa/8c/16c93fccce688ae1bde7d979ff102f7bee980d9cfeb8641bcf\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.0 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install surprise\n",
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzeK0zA9xrq0"
   },
   "source": [
    "<h4> 4.3.2.1 Transforming train data </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0l0rgL1qxrq1"
   },
   "source": [
    "- We can't give raw data (movie, user, rating) to train the model in Surprise library.\n",
    "\n",
    "\n",
    "- They have a saperate format for TRAIN and TEST data, which will be useful for training the models like SVD, KNNBaseLineOnly....etc..,in Surprise.\n",
    "\n",
    "\n",
    "- We can form the trainset from a file, or from a Pandas  DataFrame. \n",
    "http://surprise.readthedocs.io/en/stable/getting_started.html#load-dom-dataframe-py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9TA98dwxrq1"
   },
   "outputs": [],
   "source": [
    "# It is to specify how to read the dataframe.\n",
    "# for our dataframe, we don't have to specify anything extra..\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the dataframe...\n",
    "train_data = Dataset.load_from_df(reg_train[['user', 'movie', 'rating']], reader)\n",
    "\n",
    "# build the trainset from traindata.., It is of dataset format from surprise library..\n",
    "trainset = train_data.build_full_trainset() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6OTXxLz-xrq2"
   },
   "source": [
    "<h4> 4.3.2.2 Transforming test data </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwKbEi_uxrq2"
   },
   "source": [
    "- Testset is just a list of (user, movie, rating) tuples. (Order in the tuple is impotant) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "v3jqrt6lxrq2",
    "outputId": "a80dfc31-237d-4f9e-81c8-c19ae9c3538c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1129620, 2, 3), (779046, 71, 5), (808635, 71, 5)]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = list(zip(reg_test_df.user.values, reg_test_df.movie.values, reg_test_df.rating.values))\n",
    "testset[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzgDaBL_xrq8"
   },
   "source": [
    "<h2> 4.4 Applying Machine Learning models </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gbgKluZ8xrq9"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRL_TP7axrq9"
   },
   "source": [
    "-  Global dictionary that stores rmse and mape for all the models....\n",
    "\n",
    "    - It stores the metrics in a dictionary of dictionaries\n",
    "\n",
    "    > __keys__ : model names(string)\n",
    "\n",
    "    > __value__: dict(__key__ : metric, __value__ : value ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "9sKjPQMExrq9",
    "outputId": "428acbc3-a1aa-4991-9a1e-9f061b9712e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, {})"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_evaluation_train = dict()\n",
    "models_evaluation_test = dict()\n",
    "\n",
    "models_evaluation_train, models_evaluation_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ca6rt6ZixrrA"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vlx884YTxrrI"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jh6CNDb1xrrI"
   },
   "source": [
    "<h3> 4.4.1 XGBoost with initial 13 features </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDMZ35MNxrrJ"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rdZ1-h7S_gB"
   },
   "outputs": [],
   "source": [
    "def hyperpar_xgb_run(max_depths, n_estims, x_train, y_train, x_test, y_test):\n",
    "  best_test_rmse = 10\n",
    "  best_params = {}\n",
    "  best_results = {}\n",
    "  best_model = None\n",
    "\n",
    "  for d in  max_depths:\n",
    "    for est in n_estims:\n",
    "      print(f\"For max_depth = {d} and n_estimators = {est}:\")\n",
    "      print()\n",
    "      xgb_model = xgb.XGBRegressor(silent=False, n_jobs=13, max_depth=d, random_state=15, n_estimators=est)\n",
    "      train_results, test_results = run_xgboost(xgb_model, x_train, y_train, x_test, y_test)\n",
    "      if test_results['rmse'] < best_test_rmse:\n",
    "        best_params = {'max_depth': d, 'n_estimators': est}\n",
    "        best_results = {'train_results': train_results, 'test_results': test_results}\n",
    "        best_model = xgb_model\n",
    "        best_test_rmse = test_results['rmse']\n",
    "      print()\n",
    "      print()\n",
    "  \n",
    "  return (best_model, best_results['train_results'], best_results['test_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6emtuYlTA9N"
   },
   "outputs": [],
   "source": [
    "def hyperpar_surprise_run(ks, shrinkages, x_train, y_train, x_test, y_test):\n",
    "  best_test_rmse = 10\n",
    "  best_params = {}\n",
    "  best_results = {}\n",
    "  best_model = None\n",
    "\n",
    "  for k in ks:\n",
    "    for shr in shrinkages:\n",
    "\n",
    "      sim_options = {'user_based' : True,\n",
    "                'name': 'pearson_baseline',\n",
    "                'shrinkage': shr,\n",
    "                'min_support': 2\n",
    "                } \n",
    "      # we keep other parameters like regularization parameter and learning_rate as default values.\n",
    "      bsl_options = {'method': 'sgd'} \n",
    "\n",
    "      print(f\"For k = {k} and shrinkage = {shr}:\")\n",
    "      print()\n",
    "\n",
    "      sur_model = KNNBaseline(k=k, sim_options = sim_options, bsl_options = bsl_options)\n",
    "      train_results, test_results = run_surprise(sur_model, trainset, testset, verbose=True)\n",
    "      \n",
    "      if test_results['rmse'] < best_test_rmse:\n",
    "        best_params = {'k': k, 'shrinkage': shr}\n",
    "        best_results = {'train_results': train_results, 'test_results': test_results}\n",
    "        best_model = sur_model\n",
    "        best_test_rmse = test_results['rmse']\n",
    "      print()\n",
    "      print()\n",
    "  \n",
    "  return (best_model, best_results['train_results'], best_results['test_results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DoxUdAnFxrrK",
    "outputId": "82472870-9e3b-4499-9a66-dc563264ad29",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth = 2 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[08:22:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:13.179023\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.09138927836392\n",
      "MAPE :  35.06897200613277\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[08:22:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:36.028842\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0931204871714029\n",
      "MAPE :  35.011336019307755\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[08:23:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:59.370982\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0928743784669472\n",
      "MAPE :  35.077572712623514\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[08:24:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:17.045721\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.098859727116488\n",
      "MAPE :  34.63867883303405\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[08:24:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:50.551515\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.098748280947833\n",
      "MAPE :  34.70369684270626\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[08:25:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:24.241922\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0959464144169386\n",
      "MAPE :  34.87565655924422\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[08:27:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:30.198390\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.1027916170554475\n",
      "MAPE :  34.537257090757464\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[08:27:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:27.817117\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0987631253213554\n",
      "MAPE :  34.76400292474344\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[08:29:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:02:25.604804\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.13811808139467\n",
      "MAPE :  33.83242235042275\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# prepare Train data\n",
    "x_train = reg_train.drop(['user','movie','rating'], axis=1)\n",
    "y_train = reg_train['rating']\n",
    "\n",
    "# Prepare Test data\n",
    "x_test = reg_test_df.drop(['user','movie','rating'], axis=1)\n",
    "y_test = reg_test_df['rating']\n",
    "\n",
    "# running XGBoost model...\n",
    "depths = [2, 3, 5]\n",
    "estimators = [100, 300, 500]\n",
    "\n",
    "first_xbg, train_results, test_results = \\\n",
    "      hyperpar_xgb_run(depths, estimators, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "IEvkFc5JPaUl",
    "outputId": "0fd451c8-b48e-4483-93d3-c8f3af9a127c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "first_xgb = first_xbg\n",
    "models_evaluation_train['first_algo'] = train_results\n",
    "models_evaluation_test['first_algo'] = test_results\n",
    "\n",
    "xgb.plot_importance(first_xgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWm7knFrxrrO"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FUG-CnKpxrrP"
   },
   "source": [
    "<h3> 4.4.2 Suprise BaselineModel </h3>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpX853XsxrrQ"
   },
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9FkmEuTxrrR"
   },
   "source": [
    "__Predicted_rating : ( baseline prediction ) __\n",
    "\n",
    "    -  http://surprise.readthedocs.io/en/stable/basic_algorithms.html#surprise.prediction_algorithms.baseline_only.BaselineOnly \n",
    " >$   \\large {\\hat{r}_{ui} = b_{ui} =\\mu + b_u + b_i} $\n",
    "\n",
    "\n",
    "- $\\pmb \\mu $ : Average of all trainings in training data.\n",
    "- $\\pmb b_u$ : User bias\n",
    "- $\\pmb b_i$ : Item bias (movie biases) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITW64wCDxrrR"
   },
   "source": [
    "__Optimization function ( Least Squares Problem ) __\n",
    "\n",
    "    - http://surprise.readthedocs.io/en/stable/prediction_algorithms.html#baselines-estimates-configuration \n",
    "\n",
    "> $ \\large \\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - (\\mu + b_u + b_i)\\right)^2 +\n",
    "\\lambda \\left(b_u^2 + b_i^2 \\right).\\text {        [mimimize } {b_u, b_i]}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "Hxg5585nxrrS",
    "outputId": "7a7b85ed-b5f2-49da-bf38-3fdbe01f28cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Done. time taken : 0:00:05.701762 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:06.752526\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.9224990874903779\n",
      "\n",
      "MAPE : 28.69175561741864\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.999818\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0906841722187548\n",
      "\n",
      "MAPE : 35.03549054586883\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:13.456023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# options are to specify.., how to compute those user and item biases\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .001\n",
    "               }\n",
    "bsl_algo = BaselineOnly(bsl_options=bsl_options)\n",
    "# run this algorithm.., It will return the train and test results..\n",
    "bsl_train_results, bsl_test_results = run_surprise(bsl_algo, trainset, testset, verbose=True)\n",
    "\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['bsl_algo'] = bsl_train_results \n",
    "models_evaluation_test['bsl_algo'] = bsl_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64PX9U4FxrrT"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AX3Zrio7xrrU"
   },
   "source": [
    "<h3> 4.4.3 XGBoost with initial 13 features + Surprise Baseline predictor </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ab0DLIymxrrV"
   },
   "source": [
    "__Updating Train Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "eU92pNacxrrV",
    "outputId": "7b523898-464e-47d2-f794-80bb82de0855"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "      <th>bslpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174683</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.793103</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>5</td>\n",
       "      <td>3.629662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233949</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.696970</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>3</td>\n",
       "      <td>3.668190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  movie      GAvg  sur1  ...      UAvg      MAvg  rating     bslpr\n",
       "0  174683     10  3.581691   5.0  ...  3.793103  3.611111       5  3.629662\n",
       "1  233949     10  3.581691   4.0  ...  2.696970  3.611111       3  3.668190\n",
       "\n",
       "[2 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add our baseline_predicted value as our feature..\n",
    "reg_train['bslpr'] = models_evaluation_train['bsl_algo']['predictions']\n",
    "reg_train.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhhIJM6ExrrW"
   },
   "source": [
    "__Updating Test Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "yKTq0QZrxrrW",
    "outputId": "2fca496b-af73-4a17-cadd-33139ebe226e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "      <th>bslpr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1129620</td>\n",
       "      <td>2</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3</td>\n",
       "      <td>3.581691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>779046</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5</td>\n",
       "      <td>3.581691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  movie      GAvg      sur1  ...      UAvg      MAvg  rating     bslpr\n",
       "0  1129620      2  3.581691  3.581691  ...  3.581691  3.581691       3  3.581691\n",
       "1   779046     71  3.581691  3.581691  ...  3.581691  3.581691       5  3.581691\n",
       "\n",
       "[2 rows x 17 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add that baseline predicted ratings with Surprise to the test data as well\n",
    "reg_test_df['bslpr']  = models_evaluation_test['bsl_algo']['predictions']\n",
    "\n",
    "reg_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0z23w_HHxrra",
    "outputId": "2ae09add-571c-4ddf-b34d-0134590b8026",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth = 2 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[08:32:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:16.149396\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.09138927836392\n",
      "MAPE :  35.06897200613277\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[08:32:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:44.516054\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.093134643289765\n",
      "MAPE :  35.010618014376654\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[08:33:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:15.191446\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0931011282094036\n",
      "MAPE :  35.05102836393086\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[08:34:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:22.079903\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0988598032845123\n",
      "MAPE :  34.638676958245064\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[08:35:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:04.470648\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.099680873979492\n",
      "MAPE :  34.66243393859245\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[08:36:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:46.739814\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0961701839784637\n",
      "MAPE :  34.86105697868126\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[08:38:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:37.562934\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0973178093551044\n",
      "MAPE :  34.773872470287046\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[08:38:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:50.337896\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0966978667873934\n",
      "MAPE :  34.853746253554164\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[08:40:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:03:01.440167\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0997067671642191\n",
      "MAPE :  34.72029784581004\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# prepare Train data\n",
    "x_train = reg_train.drop(['user','movie','rating'], axis=1)\n",
    "y_train = reg_train['rating']\n",
    "\n",
    "# Prepare Test data\n",
    "x_test = reg_test_df.drop(['user','movie','rating'], axis=1)\n",
    "y_test = reg_test_df['rating']\n",
    "\n",
    "# running XGBoost model...\n",
    "depths = [2, 3, 5]\n",
    "estimators = [100, 300, 500]\n",
    "\n",
    "xgb_bsl, train_results, test_results = \\\n",
    "      hyperpar_xgb_run(depths, estimators, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "VznZdRs2ve1b",
    "outputId": "a116e81b-a4e9-426f-a3c6-5aaa239ddb51"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_evaluation_train['xgb_bsl'] = train_results\n",
    "models_evaluation_test['xgb_bsl'] = test_results\n",
    "\n",
    "xgb.plot_importance(xgb_bsl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xiJEJeiyxrrc"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1g0yVadzxrrh"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2w39xJPlxrrh"
   },
   "source": [
    "<h3> 4.4.4 Surprise KNNBaseline predictor </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaJlXYiKxrrh"
   },
   "outputs": [],
   "source": [
    "from surprise import KNNBaseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cdn8nTgxrrj"
   },
   "source": [
    "- KNN BASELINE\n",
    "    - http://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNBaseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2PpzK19dxrrj"
   },
   "source": [
    "- PEARSON_BASELINE SIMILARITY\n",
    "    - http://surprise.readthedocs.io/en/stable/similarities.html#surprise.similarities.pearson_baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s7uOgHb7xrrk"
   },
   "source": [
    "- SHRINKAGE\n",
    "    - _2.2 Neighborhood Models_ in http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QFn0o57Lxrrk"
   },
   "source": [
    "- __predicted Rating__ : ( ___ based on User-User similarity ___ )\n",
    "\n",
    "\\begin{align} \\hat{r}_{ui} = b_{ui} + \\frac{ \\sum\\limits_{v \\in N^k_i(u)}\n",
    "\\text{sim}(u, v) \\cdot (r_{vi} - b_{vi})} {\\sum\\limits_{v \\in\n",
    "N^k_i(u)} \\text{sim}(u, v)} \\end{align}\n",
    "\n",
    "- $\\pmb{b_{ui}}$ -  _Baseline prediction_ of (user,movie) rating\n",
    "\n",
    "- $ \\pmb {N_i^k (u)}$ - Set of __K similar__ users (neighbours) of __user (u)__ who rated __movie(i)__  \n",
    "\n",
    "- _sim (u, v)_ - __Similarity__ between users __u and v__  \n",
    "    - Generally, it will be cosine similarity or Pearson correlation coefficient. \n",
    "    - But we use __shrunk Pearson-baseline correlation coefficient__, which is based on the pearsonBaseline similarity ( we take base line predictions instead of mean rating of user/item)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G1o_o66Cxrrk"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QCM5rlkxrrl"
   },
   "source": [
    "- __ Predicted rating __ ( based on Item Item similarity ):\n",
    " \\begin{align} \\hat{r}_{ui} = b_{ui} + \\frac{ \\sum\\limits_{j \\in N^k_u(i)}\\text{sim}(i, j) \\cdot (r_{uj} - b_{uj})} {\\sum\\limits_{j \\in N^k_u(j)} \\text{sim}(i, j)} \\end{align}\n",
    "\n",
    "    -  ___Notations follows same as above (user user based predicted rating ) ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VCI_ZO0uxrrm"
   },
   "source": [
    "  <h4> 4.4.4.1 Surprise KNNBaseline with user user similarities</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6t_azidRvnxA"
   },
   "source": [
    "**I am not tuning hyper-parameters for KNNBaseline model as it takes lot of RAM and shuts the colab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "id": "wzIDc0Z9xrrm",
    "outputId": "81ba6a7b-cc72-4ee6-98b6-0c3e9424b8d1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:05:58.909797 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:24:29.529143\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.43695673554824344\n",
      "\n",
      "MAPE : 12.316741435069908\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:01.123451\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0912113839042437\n",
      "\n",
      "MAPE : 35.04687078196327\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:30:29.565376\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'user_based' : True,\n",
    "              'name': 'pearson_baseline',\n",
    "              'shrinkage': 100,\n",
    "              'min_support': 2\n",
    "              } \n",
    "# we keep other parameters like regularization parameter and learning_rate as default values.\n",
    "bsl_options = {'method': 'sgd'}\n",
    "\n",
    "knn_model = KNNBaseline(k=40, sim_options = sim_options, bsl_options = bsl_options)\n",
    "train_results, test_results = run_surprise(knn_model, trainset, testset, verbose=True)\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['knn_bsl_u'] = train_results\n",
    "models_evaluation_test['knn_bsl_u'] = test_results\n",
    "\n",
    "knn_bsl_u = knn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kd9yvmiLxrro"
   },
   "source": [
    "<h4> 4.4.4.2 Surprise KNNBaseline with movie movie similarities</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "id": "U6bjtkIUQSoS",
    "outputId": "538ade89-f3cd-42ee-f8d7-b709c65e19d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. time taken : 0:00:10.232411 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:01:44.905039\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.48336909067160244\n",
      "\n",
      "MAPE : 13.48133560351244\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:01.039677\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0913716198974626\n",
      "\n",
      "MAPE : 35.049830643994326\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:01:56.179521\n"
     ]
    }
   ],
   "source": [
    "sim_options = {'user_based' : False,\n",
    "              'name': 'pearson_baseline',\n",
    "              'shrinkage': 100,\n",
    "              'min_support': 2\n",
    "              } \n",
    "# we keep other parameters like regularization parameter and learning_rate as default values.\n",
    "bsl_options = {'method': 'sgd'}\n",
    "\n",
    "knn_model = KNNBaseline(k=40, sim_options = sim_options, bsl_options = bsl_options)\n",
    "train_results, test_results = run_surprise(knn_model, trainset, testset, verbose=True)\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['knn_bsl_m'] = train_results\n",
    "models_evaluation_test['knn_bsl_m'] = test_results\n",
    "\n",
    "knn_bsl_m = knn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fSwE4hxxrrr"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFN8SP06xrrr"
   },
   "source": [
    "<h3> 4.4.5 XGBoost with initial 13 features + Surprise Baseline predictor + KNNBaseline predictor </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-S5MhTjxrrr"
   },
   "source": [
    "- - - First we will run XGBoost with predictions from both KNN's ( that uses User\\_User and Item\\_Item similarities along with our previous features.\n",
    "\n",
    " \n",
    "- - - Then we will run XGBoost with just predictions form both knn models and preditions from our baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNs8hRmfxrrr"
   },
   "source": [
    "__Preparing Train data __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "fz7NsHUHxrrr",
    "outputId": "e10f76c0-964a-4fb4-dee3-bb12e3352fce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174683</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.793103</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>5</td>\n",
       "      <td>3.629662</td>\n",
       "      <td>4.965611</td>\n",
       "      <td>4.888374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233949</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.696970</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>3</td>\n",
       "      <td>3.668190</td>\n",
       "      <td>3.202209</td>\n",
       "      <td>3.286666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  movie      GAvg  sur1  ...  rating     bslpr  knn_bsl_u  knn_bsl_m\n",
       "0  174683     10  3.581691   5.0  ...       5  3.629662   4.965611   4.888374\n",
       "1  233949     10  3.581691   4.0  ...       3  3.668190   3.202209   3.286666\n",
       "\n",
       "[2 rows x 19 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the predicted values from both knns to this dataframe\n",
    "reg_train['knn_bsl_u'] = models_evaluation_train['knn_bsl_u']['predictions']\n",
    "reg_train['knn_bsl_m'] = models_evaluation_train['knn_bsl_m']['predictions']\n",
    "\n",
    "reg_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v_Hz6_buxrrw"
   },
   "source": [
    "__Preparing Test data  __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "BQCT1Vaexrrx",
    "outputId": "d810abbb-2730-49d8-b77f-9cd6a10f5ab1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1129620</td>\n",
       "      <td>2</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>779046</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  movie      GAvg      sur1  ...  rating     bslpr  knn_bsl_u  knn_bsl_m\n",
       "0  1129620      2  3.581691  3.581691  ...       3  3.581691   3.581691   3.581691\n",
       "1   779046     71  3.581691  3.581691  ...       5  3.581691   3.581691   3.581691\n",
       "\n",
       "[2 rows x 19 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_test_df['knn_bsl_u'] = models_evaluation_test['knn_bsl_u']['predictions']\n",
    "reg_test_df['knn_bsl_m'] = models_evaluation_test['knn_bsl_m']['predictions']\n",
    "\n",
    "reg_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wZ2khR0Oxrrz",
    "outputId": "a99ed89e-049d-4ea7-a79a-9b44dc59a9d7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth = 2 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[09:16:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:19.220906\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.09138927836392\n",
      "MAPE :  35.06897200613277\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[09:16:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:55.873750\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0931241068855206\n",
      "MAPE :  35.00846024128173\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[09:17:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:32.224078\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0930482793509584\n",
      "MAPE :  35.051497329985736\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[09:19:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:27.315772\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.098859789256981\n",
      "MAPE :  34.63867828235943\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[09:20:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:19.290493\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0994927664099066\n",
      "MAPE :  34.66551694514506\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[09:21:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:02:07.802094\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0968075029229103\n",
      "MAPE :  34.81599303066777\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[09:23:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:45.209806\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0975878928816025\n",
      "MAPE :  34.76418517536958\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[09:24:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:02:12.478724\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.1070793082293797\n",
      "MAPE :  34.427250527231145\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[09:26:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:03:40.539378\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.113712226855898\n",
      "MAPE :  34.262633242836685\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# prepare Train data\n",
    "x_train = reg_train.drop(['user','movie','rating'], axis=1)\n",
    "y_train = reg_train['rating']\n",
    "\n",
    "# Prepare Test data\n",
    "x_test = reg_test_df.drop(['user','movie','rating'], axis=1)\n",
    "y_test = reg_test_df['rating']\n",
    "\n",
    "# running XGBoost model...\n",
    "depths = [2, 3, 5]\n",
    "estimators = [100, 300, 500]\n",
    "\n",
    "xgb_knn_bsl, train_results, test_results = \\\n",
    "      hyperpar_xgb_run(depths, estimators, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "_4DfDYur8cjb",
    "outputId": "159d85d7-47ca-4939-cb55-c243ae2c0c6f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store the results in models_evaluations dictionaries\n",
    "models_evaluation_train['xgb_knn_bsl'] = train_results\n",
    "models_evaluation_test['xgb_knn_bsl'] = test_results\n",
    "\n",
    "xgb.plot_importance(xgb_knn_bsl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOZ62nT7xrr0"
   },
   "source": [
    "<h3> 4.4.6 Matrix Factorization Techniques </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8TKj6Ggxrr1"
   },
   "source": [
    "<h4> 4.4.6.1 SVD Matrix Factorization User Movie intractions </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVKeXrzLxrr1"
   },
   "outputs": [],
   "source": [
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMjw1PJyxrr3"
   },
   "source": [
    "http://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQia_R3Lxrr3"
   },
   "source": [
    "- __ Predicted Rating : __\n",
    "    - \n",
    "    - $ \\large  \\hat r_{ui} = \\mu + b_u + b_i + q_i^Tp_u $\n",
    "    \n",
    "        - $\\pmb q_i$ - Representation of item(movie) in latent factor space\n",
    "        \n",
    "        - $\\pmb p_u$ - Representation of user in new latent factor space\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C9iP5Kvyxrr3"
   },
   "source": [
    "- A BASIC MATRIX FACTORIZATION MODEL in  https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N4djzeu0xrr3"
   },
   "source": [
    "- __Optimization problem with user item interactions and regularization (to avoid overfitting)__\n",
    "    - \n",
    "    - $\\large \\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - \\hat{r}_{ui} \\right)^2 +\n",
    "\\lambda\\left(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2\\right) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "colab_type": "code",
    "id": "SDCetsu-xrr3",
    "outputId": "b0e1ce98-456c-4c2c-a613-efa1e11e0a00",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Done. time taken : 0:00:45.181135 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:07.762425\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.6733835409203514\n",
      "\n",
      "MAPE : 20.050274566430474\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:00.965977\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.090732194420088\n",
      "\n",
      "MAPE : 34.974384804732125\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:00:53.911848\n"
     ]
    }
   ],
   "source": [
    "# initiallize the model\n",
    "svd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\n",
    "svd_train_results, svd_test_results = run_surprise(svd, trainset, testset, verbose=True)\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['svd'] = svd_train_results \n",
    "models_evaluation_test['svd'] = svd_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZUujRuPYxrr5"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmi0We7exrr6"
   },
   "source": [
    "  <h4> 4.4.6.2 SVD Matrix Factorization with implicit feedback from user ( user rated movies ) </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V4gpAlPxrr6"
   },
   "outputs": [],
   "source": [
    "from surprise import SVDpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJll_qYrxrr9"
   },
   "source": [
    "- ----->  2.5 Implicit Feedback in http://courses.ischool.berkeley.edu/i290-dm/s11/SECURE/a1-koren.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mbgkdFWUxrr-"
   },
   "source": [
    "- __ Predicted Rating : __\n",
    "    - \n",
    "    - $ \\large \\hat{r}_{ui} = \\mu + b_u + b_i + q_i^T\\left(p_u +\n",
    "    |I_u|^{-\\frac{1}{2}} \\sum_{j \\in I_u}y_j\\right) $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACwlEGXixrr-"
   },
   "source": [
    " - $ \\pmb{I_u}$ --- the set of all items rated by user u\n",
    "\n",
    "- $\\pmb{y_j}$ --- Our new set of item factors that capture implicit ratings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCAxmVdfxrr_"
   },
   "source": [
    "- __Optimization problem with user item interactions and regularization (to avoid overfitting)__\n",
    "    - \n",
    "    - $ \\large \\sum_{r_{ui} \\in R_{train}} \\left(r_{ui} - \\hat{r}_{ui} \\right)^2 +\n",
    "\\lambda\\left(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2 + ||y_j||^2\\right) $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "colab_type": "code",
    "id": "Ajw3SQdZxrr_",
    "outputId": "06c400ee-3efa-406c-b45a-7c2f9e31b434",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      "Done. time taken : 0:28:43.713504 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:01:19.153760\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.6551590292181674\n",
      "\n",
      "MAPE : 18.934401555091707\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:01.099742\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0911289051014106\n",
      "\n",
      "MAPE : 34.91855569731148\n",
      "\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:30:03.970648\n"
     ]
    }
   ],
   "source": [
    "# initiallize the model\n",
    "svdpp = SVDpp(n_factors=50, random_state=15, verbose=True)\n",
    "svdpp_train_results, svdpp_test_results = run_surprise(svdpp, trainset, testset, verbose=True)\n",
    "\n",
    "# Just store these error metrics in our models_evaluation datastructure\n",
    "models_evaluation_train['svdpp'] = svdpp_train_results \n",
    "models_evaluation_test['svdpp'] = svdpp_test_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olxsWgLNxrsB"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Ho6vTM4xrsB"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAlGZGj_xrsB"
   },
   "source": [
    "<h3> 4.4.7 XgBoost with 13 features + Surprise Baseline + Surprise KNNbaseline + MF Techniques </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "woIqb160xrsC"
   },
   "source": [
    "__Preparing Train data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "JrQkQ3u3xrsD",
    "outputId": "c3eaa36b-3e49-4d37-b93d-24984f89cbdb",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "      <th>svd</th>\n",
       "      <th>svdpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174683</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.793103</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>5</td>\n",
       "      <td>3.629662</td>\n",
       "      <td>4.965611</td>\n",
       "      <td>4.888374</td>\n",
       "      <td>3.954657</td>\n",
       "      <td>3.938250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233949</td>\n",
       "      <td>10</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.696970</td>\n",
       "      <td>3.611111</td>\n",
       "      <td>3</td>\n",
       "      <td>3.668190</td>\n",
       "      <td>3.202209</td>\n",
       "      <td>3.286666</td>\n",
       "      <td>3.655824</td>\n",
       "      <td>3.429631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user  movie      GAvg  sur1  ...  knn_bsl_u  knn_bsl_m       svd     svdpp\n",
       "0  174683     10  3.581691   5.0  ...   4.965611   4.888374  3.954657  3.938250\n",
       "1  233949     10  3.581691   4.0  ...   3.202209   3.286666  3.655824  3.429631\n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the predicted values from both knns to this dataframe\n",
    "reg_train['svd'] = models_evaluation_train['svd']['predictions']\n",
    "reg_train['svdpp'] = models_evaluation_train['svdpp']['predictions']\n",
    "\n",
    "reg_train.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T87HaSHExrsE"
   },
   "source": [
    "__Preparing Test data  __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "5YFZJ6sqxrsE",
    "outputId": "0e830e29-fd42-4c61-d589-971365a7a4e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>GAvg</th>\n",
       "      <th>sur1</th>\n",
       "      <th>sur2</th>\n",
       "      <th>sur3</th>\n",
       "      <th>sur4</th>\n",
       "      <th>sur5</th>\n",
       "      <th>smr1</th>\n",
       "      <th>smr2</th>\n",
       "      <th>smr3</th>\n",
       "      <th>smr4</th>\n",
       "      <th>smr5</th>\n",
       "      <th>UAvg</th>\n",
       "      <th>MAvg</th>\n",
       "      <th>rating</th>\n",
       "      <th>bslpr</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "      <th>svd</th>\n",
       "      <th>svdpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1129620</td>\n",
       "      <td>2</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>779046</td>\n",
       "      <td>71</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>5</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "      <td>3.581691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user  movie      GAvg      sur1  ...  knn_bsl_u  knn_bsl_m       svd     svdpp\n",
       "0  1129620      2  3.581691  3.581691  ...   3.581691   3.581691  3.581691  3.581691\n",
       "1   779046     71  3.581691  3.581691  ...   3.581691   3.581691  3.581691  3.581691\n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_test_df['svd'] = models_evaluation_test['svd']['predictions']\n",
    "reg_test_df['svdpp'] = models_evaluation_test['svdpp']['predictions']\n",
    "\n",
    "reg_test_df.head(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t7zUJRT3xrsG"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8txfT1mCxrsG",
    "outputId": "63a5ceeb-742f-4354-d9a6-be42778a8b97",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth = 2 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[10:12:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:21.106084\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.09138927836392\n",
      "MAPE :  35.06897200613277\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[10:13:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:03.937359\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.093099664260115\n",
      "MAPE :  35.01088272957672\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[10:14:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:40.623572\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0931467413901013\n",
      "MAPE :  35.036577477453804\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[10:15:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:31.351089\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.098859785732006\n",
      "MAPE :  34.63867795915466\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[10:16:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:31.134902\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0993454310740403\n",
      "MAPE :  34.67267199059955\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[10:18:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:02:31.690010\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0971565064739206\n",
      "MAPE :  34.78807593466235\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[10:20:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:52.827404\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.098122117491522\n",
      "MAPE :  34.74413304466805\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[10:21:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:02:38.036764\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0972773024173994\n",
      "MAPE :  34.817992585063834\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[10:24:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:04:25.687974\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.09649354877175\n",
      "MAPE :  34.881205155882235\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare x_train and y_train\n",
    "x_train = reg_train.drop(['user', 'movie', 'rating',], axis=1)\n",
    "y_train = reg_train['rating']\n",
    "\n",
    "# prepare test data\n",
    "x_test = reg_test_df.drop(['user', 'movie', 'rating'], axis=1)\n",
    "y_test = reg_test_df['rating']\n",
    "\n",
    "depths = [2, 3, 5]\n",
    "estimators = [100, 300, 500]\n",
    "\n",
    "xgb_final, train_results, test_results = \\\n",
    "      hyperpar_xgb_run(depths, estimators, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "f3mC_1XyUk8E",
    "outputId": "ab182363-a0f6-4580-9f32-b9bce70fad4a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_evaluation_train['xgb_final'] = train_results\n",
    "models_evaluation_test['xgb_final'] = test_results\n",
    "\n",
    "\n",
    "xgb.plot_importance(xgb_final)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NN-0BKnXxrsI"
   },
   "source": [
    "<h3> 4.4.8 XgBoost with Surprise Baseline + Surprise KNNbaseline + MF Techniques </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "y0RFoUIvxrsI",
    "outputId": "e9c408e2-d0f1-4fbf-8ecc-93cc83227660",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For max_depth = 2 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[10:29:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:12.535367\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0990755568997919\n",
      "MAPE :  35.43721353310102\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[10:29:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:36.051310\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0992905204017764\n",
      "MAPE :  35.43298225022281\n",
      "\n",
      "\n",
      "For max_depth = 2 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[10:30:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:56.145899\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0993720962452453\n",
      "MAPE :  35.430003641230435\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[10:31:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:16.719267\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0990283968457084\n",
      "MAPE :  35.4455659963039\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[10:31:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:49.767716\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0993917758942733\n",
      "MAPE :  35.431035386304735\n",
      "\n",
      "\n",
      "For max_depth = 3 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[10:32:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:22.985672\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0994393757313303\n",
      "MAPE :  35.43414384615214\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 100:\n",
      "\n",
      "Training the model..\n",
      "[10:33:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:00:30.633241\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.099042863223025\n",
      "MAPE :  35.44897132738989\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 300:\n",
      "\n",
      "Training the model..\n",
      "[10:34:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:01:30.005296\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.099508256179244\n",
      "MAPE :  35.430674081513075\n",
      "\n",
      "\n",
      "For max_depth = 5 and n_estimators = 500:\n",
      "\n",
      "Training the model..\n",
      "[10:36:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Done. Time taken : 0:02:28.619711\n",
      "\n",
      "Done \n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "Evaluating Test data\n",
      "\n",
      "TEST DATA\n",
      "------------------------------\n",
      "RMSE :  1.0995350276867712\n",
      "MAPE :  35.4299280978735\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare train data\n",
    "x_train = reg_train[['knn_bsl_u', 'knn_bsl_m', 'svd', 'svdpp']]\n",
    "y_train = reg_train['rating']\n",
    "\n",
    "# test data\n",
    "x_test = reg_test_df[['knn_bsl_u', 'knn_bsl_m', 'svd', 'svdpp']]\n",
    "y_test = reg_test_df['rating']\n",
    "\n",
    "depths = [2, 3, 5]\n",
    "estimators = [100, 300, 500]\n",
    "\n",
    "xgb_all_models, train_results, test_results = \\\n",
    "      hyperpar_xgb_run(depths, estimators, x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "ZD6bNBb1VJwr",
    "outputId": "b25ef055-2181-49e7-f9e8-f3ad48691c50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAEWCAYAAAA3h9P4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_evaluation_train['xgb_all_models'] = train_results\n",
    "models_evaluation_test['xgb_all_models'] = test_results\n",
    "\n",
    "xgb.plot_importance(xgb_all_models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aqrjuykxrsQ"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RI_N9U9ZxrsR"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yd0ye7O1xrsR"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DxsS3JKnxrsS",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rmse_train_results = dict([(x, y['rmse']) for x, y in models_evaluation_train.items()])\n",
    "rmse_test_results = dict([(x, y['rmse']) for x, y in models_evaluation_test.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AhrGf2Lm7qhH"
   },
   "outputs": [],
   "source": [
    "models = {'first_algo': first_xgb, 'bsl_algo': bsl_algo, 'xgb_bsl': xgb_bsl,\n",
    "          'knn_bsl_u': knn_bsl_u, 'knn_bsl_m': knn_bsl_m, 'xgb_knn_bsl': xgb_knn_bsl,\n",
    "          'svd': svd, 'svdpp': svdpp, 'xgb_all_models': xgb_all_models, 'xgb_final': xgb_final}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y81d-P1f-LUt"
   },
   "outputs": [],
   "source": [
    "hyper_params = {'first_algo': 'depth: 2, n_estim: 100', 'bsl_algo': '-',\\\n",
    "                'xgb_bsl': 'depth: 2, n_estim: 100', 'knn_bsl_u': 'shrinkage: 100, k: 40',\\\n",
    "                'knn_bsl_m': 'shrinkage: 100, k: 40', 'xgb_knn_bsl': 'depth: 2, n_estim: 100',\\\n",
    "                'svd': 'n_factors: 100', 'svdpp': 'n_factors: 50',\\\n",
    "                'xgb_all_models': 'depth: 3, n_estim: 100', 'xgb_final': 'depth: 2, n_estim: 100'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "U_3TSpH39S02",
    "outputId": "cee4bef1-77e9-4a21-da92-783247c58ba2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------------+---------------------+--------------------+\n",
      "|     Model      |      hyper-params      |      Train RMSE     |     Test RMSE      |\n",
      "+----------------+------------------------+---------------------+--------------------+\n",
      "|   first_algo   | depth: 2, n_estim: 100 |  0.8627553985802527 |  1.09138927836392  |\n",
      "|    bsl_algo    |           -            |  0.9224990874903779 | 1.0906841722187548 |\n",
      "|    xgb_bsl     | depth: 2, n_estim: 100 |  0.8627553985802527 |  1.09138927836392  |\n",
      "|   knn_bsl_u    | shrinkage: 100, k: 40  | 0.43695673554824344 | 1.0912113839042437 |\n",
      "|   knn_bsl_m    | shrinkage: 100, k: 40  | 0.48336909067160244 | 1.0913716198974626 |\n",
      "|  xgb_knn_bsl   | depth: 2, n_estim: 100 |  0.8627553985802527 |  1.09138927836392  |\n",
      "|      svd       |     n_factors: 100     |  0.6733835409203514 | 1.090732194420088  |\n",
      "|     svdpp      |     n_factors: 50      |  0.6551590292181674 | 1.0911289051014106 |\n",
      "| xgb_all_models | depth: 3, n_estim: 100 |  1.0800774427028477 | 1.0990283968457084 |\n",
      "|   xgb_final    | depth: 2, n_estim: 100 |  0.8627553985802527 |  1.09138927836392  |\n",
      "+----------------+------------------------+---------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "\n",
    "table.field_names = ['Model', 'hyper-params', 'Train RMSE', 'Test RMSE']\n",
    "for key in models.keys():\n",
    "  table.add_row([key, hyper_params[key], rmse_train_results[key], rmse_test_results[key]])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NXNT_fUrxrsX"
   },
   "source": [
    " **Conclusion:**\n",
    " - **Took 25K users and 2.5K movies to prepare Train data and 12.5K users and 1.25K movies to prepare Test data.**\n",
    " - **Optimized the code for preperation of Train data and checked if it gives any different results. Preparing Train data took lot of time (~ 27 hours) even after optimising the code. (This is done in my PC as Colab wont allow long runs)**\n",
    " - **The results are not satisfactory even after hyper-parameter tuning the XGBoost Models. Every model's test RMSE is around 1.09 and adding additional features seems to be not improving the RMSE.**\n",
    " - **Surprise Baseline model gave best RMSE among all the models but there is no significant difference between models performances to declare it as the best.**\n",
    " - **User Average and movie Average are important features in all of the XGBoost models. So User bias is an important feature for predicting the rating of a cell**\n",
    " - **KNN models seems to be overfitting. Hyper-parameter tuning is not done on them because the session fails due to exceed in memory while doing the hyper-parameter tuning (even with 24GB RAM).**\n",
    " - **Increase in data is solution for better results but not able to do in time as my PC is a low end PC and Colab wont allow such long runs of session. (Preparing Train data in my PC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJRprhvZVb1A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Netflix_Movie.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
