{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WROuP70HpYRh"
   },
   "source": [
    "# Taxi demand prediction in New York City\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "9JV2NtDclbYR",
    "outputId": "b8f0ca33-1d5b-402c-edf0-b873b793002e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /gdrive\n",
      "/gdrive/My Drive/Data_Notebooks\n"
     ]
    }
   ],
   "source": [
    "# Running in Google Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive/My\\ Drive/Data_Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tt07FBdUzNw6"
   },
   "source": [
    "**Removing all EDA Cells and plotting cells and directly adding features and cleaning the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "KwvQLV8ypYRk",
    "outputId": "efc1583d-1c1a-47b2-88fa-20ca482f50a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gpxpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/d3/ce52e67771929de455e76655365a4935a2f369f76dfb0d70c20a308ec463/gpxpy-1.3.5.tar.gz (105kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: gpxpy\n",
      "  Building wheel for gpxpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gpxpy: filename=gpxpy-1.3.5-cp36-none-any.whl size=40315 sha256=b18a631aa6b0a64fdc3971423d8aeb804f5297db5667627654801c7c90519a65\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/f0/5e/b8e85979e66efec3eaa0e47fbc5274db99fd1a07befd1b2aa4\n",
      "Successfully built gpxpy\n",
      "Installing collected packages: gpxpy\n",
      "Successfully installed gpxpy-1.3.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install gpxpy\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import folium\n",
    "\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "\n",
    "import gpxpy.geo\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import math\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "3JZx1AovpYRr",
    "outputId": "8e2bc88d-d08e-493c-fabe-3de80b89fcbb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'pickup_longitude',\n",
      "       'pickup_latitude', 'RateCodeID', 'store_and_fwd_flag',\n",
      "       'dropoff_longitude', 'dropoff_latitude', 'payment_type', 'fare_amount',\n",
      "       'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
      "       'improvement_surcharge', 'total_amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Looking at the features\n",
    "# dask dataframe  : # https://github.com/dask/dask-tutorial/blob/master/07_dataframe.ipynb\n",
    "month = dd.read_csv('yellow_tripdata_2015-01.csv')\n",
    "print(month.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSmVwmMJpYSO"
   },
   "source": [
    "### Trip Durations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuilRJY1pYSP"
   },
   "source": [
    "<p style=\"font-size:18px\">According to NYC Taxi &amp; Limousine Commision Regulations <b style= \"color:blue\">the maximum allowed trip duration in a 24 hour interval is 12 hours.</b> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Qa9aMyFpYSQ"
   },
   "outputs": [],
   "source": [
    "#The timestamps are converted to unix so as to get duration(trip-time) & speed also pickup-times in unix are used while binning \n",
    "\n",
    "# in out data we have time in the formate \"YYYY-MM-DD HH:MM:SS\" we convert thiss sting to python time formate and then into unix time stamp\n",
    "# https://stackoverflow.com/a/27914405\n",
    "def convert_to_unix(s):\n",
    "    return time.mktime(datetime.datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "\n",
    "\n",
    "\n",
    "# we return a data frame which contains the columns\n",
    "# 1.'passenger_count' : self explanatory\n",
    "# 2.'trip_distance' : self explanatory\n",
    "# 3.'pickup_longitude' : self explanatory\n",
    "# 4.'pickup_latitude' : self explanatory\n",
    "# 5.'dropoff_longitude' : self explanatory\n",
    "# 6.'dropoff_latitude' : self explanatory\n",
    "# 7.'total_amount' : total fair that was paid\n",
    "# 8.'trip_times' : duration of each trip\n",
    "# 9.'pickup_times : pickup time converted into unix time \n",
    "# 10.'Speed' : velocity of each trip\n",
    "def return_with_trip_times(month):\n",
    "    duration = month[['tpep_pickup_datetime','tpep_dropoff_datetime']].compute()\n",
    "    #pickups and dropoffs to unix time\n",
    "    duration_pickup = [convert_to_unix(x) for x in duration['tpep_pickup_datetime'].values]\n",
    "    duration_drop = [convert_to_unix(x) for x in duration['tpep_dropoff_datetime'].values]\n",
    "    #calculate duration of trips\n",
    "    durations = (np.array(duration_drop) - np.array(duration_pickup))/float(60)\n",
    "\n",
    "    #append durations of trips and speed in miles/hr to a new dataframe\n",
    "    new_frame = month[['passenger_count','trip_distance','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','total_amount']].compute()\n",
    "    \n",
    "    new_frame['trip_times'] = durations\n",
    "    new_frame['pickup_times'] = duration_pickup\n",
    "    new_frame['Speed'] = 60*(new_frame['trip_distance']/new_frame['trip_times'])\n",
    "    \n",
    "    return new_frame\n",
    "\n",
    "# print(frame_with_durations.head())\n",
    "#  passenger_count\ttrip_distance\tpickup_longitude\tpickup_latitude\tdropoff_longitude\tdropoff_latitude\ttotal_amount\ttrip_times\tpickup_times\tSpeed\n",
    "#   1                  1.59\t      -73.993896        \t40.750111    \t-73.974785      \t40.750618           \t17.05   \t 18.050000\t1.421329e+09\t5.285319\n",
    "#   1               \t3.30    \t-74.001648      \t40.724243   \t-73.994415      \t40.759109           \t17.80   \t19.833333\t1.420902e+09\t9.983193\n",
    "#   1               \t1.80     \t-73.963341      \t40.802788     \t-73.951820      \t40.824413           \t10.80   \t10.050000\t1.420902e+09\t10.746269\n",
    "#   1               \t0.50    \t-74.009087      \t40.713818    \t-74.004326       \t40.719986           \t4.80    \t1.866667\t1.420902e+09\t16.071429\n",
    "#   1               \t3.00    \t-73.971176      \t40.762428    \t-74.004181      \t40.742653           \t16.30   \t19.316667\t1.420902e+09\t9.318378\n",
    "frame_with_durations = return_with_trip_times(month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlvWCK4PpYT7"
   },
   "source": [
    "## Remove all outliers/erronous points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers are removed based on the EDA done in original notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPORvXJHpYT8"
   },
   "outputs": [],
   "source": [
    "#removing all outliers based on our univariate analysis above\n",
    "def remove_outliers(new_frame):\n",
    "\n",
    "    \n",
    "    a = new_frame.shape[0]\n",
    "    print (\"Number of pickup records = \",a)\n",
    "    temp_frame = new_frame[((new_frame.dropoff_longitude >= -74.15) & (new_frame.dropoff_longitude <= -73.7004) &\\\n",
    "                       (new_frame.dropoff_latitude >= 40.5774) & (new_frame.dropoff_latitude <= 40.9176)) & \\\n",
    "                       ((new_frame.pickup_longitude >= -74.15) & (new_frame.pickup_latitude >= 40.5774)& \\\n",
    "                       (new_frame.pickup_longitude <= -73.7004) & (new_frame.pickup_latitude <= 40.9176))]\n",
    "    b = temp_frame.shape[0]\n",
    "    print (\"Number of outlier coordinates lying outside NY boundaries:\",(a-b))\n",
    "\n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.trip_times > 0) & (new_frame.trip_times < 720)]\n",
    "    c = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from trip times analysis:\",(a-c))\n",
    "    \n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.trip_distance > 0) & (new_frame.trip_distance < 23)]\n",
    "    d = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from trip distance analysis:\",(a-d))\n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.Speed <= 65) & (new_frame.Speed >= 0)]\n",
    "    e = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from speed analysis:\",(a-e))\n",
    "    \n",
    "    temp_frame = new_frame[(new_frame.total_amount <1000) & (new_frame.total_amount >0)]\n",
    "    f = temp_frame.shape[0]\n",
    "    print (\"Number of outliers from fare analysis:\",(a-f))\n",
    "    \n",
    "    \n",
    "    new_frame = new_frame[((new_frame.dropoff_longitude >= -74.15) & (new_frame.dropoff_longitude <= -73.7004) &\\\n",
    "                       (new_frame.dropoff_latitude >= 40.5774) & (new_frame.dropoff_latitude <= 40.9176)) & \\\n",
    "                       ((new_frame.pickup_longitude >= -74.15) & (new_frame.pickup_latitude >= 40.5774)& \\\n",
    "                       (new_frame.pickup_longitude <= -73.7004) & (new_frame.pickup_latitude <= 40.9176))]\n",
    "    \n",
    "    new_frame = new_frame[(new_frame.trip_times > 0) & (new_frame.trip_times < 720)]\n",
    "    new_frame = new_frame[(new_frame.trip_distance > 0) & (new_frame.trip_distance < 23)]\n",
    "    new_frame = new_frame[(new_frame.Speed < 45.31) & (new_frame.Speed > 0)]\n",
    "    new_frame = new_frame[(new_frame.total_amount <1000) & (new_frame.total_amount >0)]\n",
    "    \n",
    "    print (\"Total outliers removed\",a - new_frame.shape[0])\n",
    "    print (\"---\")\n",
    "    return new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "gLt_0naFpYT-",
    "outputId": "6140ec83-48c3-4842-9351-3b8fed9d8be7",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing outliers in the month of Jan-2015\n",
      "----\n",
      "Number of pickup records =  12748986\n",
      "Number of outlier coordinates lying outside NY boundaries: 293919\n",
      "Number of outliers from trip times analysis: 23889\n",
      "Number of outliers from trip distance analysis: 92597\n",
      "Number of outliers from speed analysis: 24473\n",
      "Number of outliers from fare analysis: 5275\n",
      "Total outliers removed 377910\n",
      "---\n",
      "fraction of data points that remain after removing outliers 0.9703576425607495\n"
     ]
    }
   ],
   "source": [
    "print (\"Removing outliers in the month of Jan-2015\")\n",
    "print (\"----\")\n",
    "frame_with_durations_outliers_removed = remove_outliers(frame_with_durations)\n",
    "print(\"fraction of data points that remain after removing outliers\", float(len(frame_with_durations_outliers_removed))/len(frame_with_durations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiSR_ZaspYUA"
   },
   "source": [
    "# Data-preperation\n",
    "## Clustering/Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdy3QNcupYUB",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#trying different cluster sizes to choose the right K in K-means\n",
    "coords = frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']].values\n",
    "neighbours=[]\n",
    "\n",
    "def find_min_distance(cluster_centers, cluster_len):\n",
    "    nice_points = 0\n",
    "    wrong_points = 0\n",
    "    less2 = []\n",
    "    more2 = []\n",
    "    min_dist=1000\n",
    "    for i in range(0, cluster_len):\n",
    "        nice_points = 0\n",
    "        wrong_points = 0\n",
    "        for j in range(0, cluster_len):\n",
    "            if j!=i:\n",
    "                distance = gpxpy.geo.haversine_distance(cluster_centers[i][0], cluster_centers[i][1],cluster_centers[j][0], cluster_centers[j][1])\n",
    "                min_dist = min(min_dist,distance/(1.60934*1000))\n",
    "                if (distance/(1.60934*1000)) <= 2:\n",
    "                    nice_points +=1\n",
    "                else:\n",
    "                    wrong_points += 1\n",
    "        less2.append(nice_points)\n",
    "        more2.append(wrong_points)\n",
    "    neighbours.append(less2)\n",
    "    print (\"On choosing a cluster size of \",cluster_len,\"\\nAvg. Number of Clusters within the vicinity (i.e. intercluster-distance < 2):\", np.ceil(sum(less2)/len(less2)), \"\\nAvg. Number of Clusters outside the vicinity (i.e. intercluster-distance > 2):\", np.ceil(sum(more2)/len(more2)),\"\\nMin inter-cluster distance = \",min_dist,\"\\n---\")\n",
    "\n",
    "def find_clusters(increment):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=increment, batch_size=10000,random_state=42).fit(coords)\n",
    "    frame_with_durations_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']])\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    cluster_len = len(cluster_centers)\n",
    "    return cluster_centers, cluster_len\n",
    "\n",
    "# we need to choose number of clusters so that, there are more number of cluster regions \n",
    "#that are close to any cluster center\n",
    "# and make sure that the minimum inter cluster should not be very less\n",
    "# for increment in range(10, 100, 10):\n",
    "#     cluster_centers, cluster_len = find_clusters(increment)\n",
    "#     find_min_distance(cluster_centers, cluster_len)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvSvm-37yqK8"
   },
   "source": [
    "### Getting clusters for k=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U9hu-gmfpYUF"
   },
   "outputs": [],
   "source": [
    "# Getting 30 clusters using the kmeans \n",
    "kmeans = MiniBatchKMeans(n_clusters=30, batch_size=10000,random_state=0).fit(coords)\n",
    "frame_with_durations_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r-RK9PzspYUP"
   },
   "source": [
    "## Time-binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhGxh1VXpYUQ"
   },
   "outputs": [],
   "source": [
    "#Refer:https://www.unixtimestamp.com/\n",
    "# 1420070400 : 2015-01-01 00:00:00 \n",
    "# 1422748800 : 2015-02-01 00:00:00 \n",
    "# 1425168000 : 2015-03-01 00:00:00\n",
    "# 1427846400 : 2015-04-01 00:00:00 \n",
    "# 1430438400 : 2015-05-01 00:00:00 \n",
    "# 1433116800 : 2015-06-01 00:00:00\n",
    "\n",
    "# 1451606400 : 2016-01-01 00:00:00 \n",
    "# 1454284800 : 2016-02-01 00:00:00 \n",
    "# 1456790400 : 2016-03-01 00:00:00\n",
    "# 1459468800 : 2016-04-01 00:00:00 \n",
    "# 1462060800 : 2016-05-01 00:00:00 \n",
    "# 1464739200 : 2016-06-01 00:00:00\n",
    "\n",
    "def add_pickup_bins(frame,month,year):\n",
    "    unix_pickup_times=[i for i in frame['pickup_times'].values]\n",
    "    unix_times = [[1420070400,1422748800,1425168000,1427846400,1430438400,1433116800],\\\n",
    "                    [1451606400,1454284800,1456790400,1459468800,1462060800,1464739200]]\n",
    "    \n",
    "    start_pickup_unix=unix_times[year-2015][month-1]\n",
    "    # https://www.timeanddate.com/time/zones/est\n",
    "    # (int((i-start_pickup_unix)/600)+33) : our unix time is in gmt to we are converting it to est\n",
    "    tenminutewise_binned_unix_pickup_times=[(int((i-start_pickup_unix)/600)+33) for i in unix_pickup_times]\n",
    "    frame['pickup_bins'] = np.array(tenminutewise_binned_unix_pickup_times)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9bO_QAAGpYUR"
   },
   "outputs": [],
   "source": [
    "# clustering, making pickup bins and grouping by pickup cluster and pickup bins\n",
    "frame_with_durations_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']])\n",
    "jan_2015_frame = add_pickup_bins(frame_with_durations_outliers_removed,1,2015)\n",
    "jan_2015_groupby = jan_2015_frame[['pickup_cluster','pickup_bins','trip_distance']].groupby(['pickup_cluster','pickup_bins']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "Q56tfNUmpYUW",
    "outputId": "5d3721e4-fe0b-424b-9f1f-c58352a39888"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>pickup_bins</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>33</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            trip_distance\n",
       "pickup_cluster pickup_bins               \n",
       "0              33                     138\n",
       "               34                     262\n",
       "               35                     311\n",
       "               36                     325\n",
       "               37                     381"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hear the trip_distance represents the number of pickups that are happend in that particular 10min intravel\n",
    "# this data frame has two indices\n",
    "# primary index: pickup_cluster (cluster number)\n",
    "# secondary index : pickup_bins (we devid whole months time into 10min intravels 24*31*60/10 =4464bins)\n",
    "jan_2015_groupby.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "sLMjW_depYUa",
    "outputId": "0e0526c6-7456-4890-ced8-8f7a3adc31f0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return with trip times..\n",
      "Remove outliers..\n",
      "Number of pickup records =  10906858\n",
      "Number of outlier coordinates lying outside NY boundaries: 214677\n",
      "Number of outliers from trip times analysis: 27190\n",
      "Number of outliers from trip distance analysis: 79742\n",
      "Number of outliers from speed analysis: 21047\n",
      "Number of outliers from fare analysis: 4991\n",
      "Total outliers removed 297784\n",
      "---\n",
      "Estimating clusters..\n",
      "Final groupbying..\n",
      "Return with trip times..\n",
      "Remove outliers..\n",
      "Number of pickup records =  11382049\n",
      "Number of outlier coordinates lying outside NY boundaries: 223161\n",
      "Number of outliers from trip times analysis: 27670\n",
      "Number of outliers from trip distance analysis: 81902\n",
      "Number of outliers from speed analysis: 22437\n",
      "Number of outliers from fare analysis: 5476\n",
      "Total outliers removed 308177\n",
      "---\n",
      "Estimating clusters..\n",
      "Final groupbying..\n",
      "Return with trip times..\n",
      "Remove outliers..\n",
      "Number of pickup records =  12210952\n",
      "Number of outlier coordinates lying outside NY boundaries: 232444\n",
      "Number of outliers from trip times analysis: 30868\n",
      "Number of outliers from trip distance analysis: 87318\n",
      "Number of outliers from speed analysis: 23889\n",
      "Number of outliers from fare analysis: 5859\n",
      "Total outliers removed 324635\n",
      "---\n",
      "Estimating clusters..\n",
      "Final groupbying..\n"
     ]
    }
   ],
   "source": [
    "# upto now we cleaned data and prepared data for the month 2015,\n",
    "\n",
    "# now do the same operations for months Jan, Feb, March of 2016\n",
    "# 1. get the dataframe which inlcudes only required colums\n",
    "# 2. adding trip times, speed, unix time stamp of pickup_time\n",
    "# 4. remove the outliers based on trip_times, speed, trip_duration, total_amount\n",
    "# 5. add pickup_cluster to each data point\n",
    "# 6. add pickup_bin (index of 10min intravel to which that trip belongs to)\n",
    "# 7. group by data, based on 'pickup_cluster' and 'pickuo_bin'\n",
    "\n",
    "# Data Preparation for the months of Jan,Feb and March 2016\n",
    "def datapreparation(month,kmeans,month_no,year_no):\n",
    "    \n",
    "    print (\"Return with trip times..\")\n",
    "\n",
    "    frame_with_durations = return_with_trip_times(month)\n",
    "    \n",
    "    print (\"Remove outliers..\")\n",
    "    frame_with_durations_outliers_removed = remove_outliers(frame_with_durations)\n",
    "    \n",
    "    print (\"Estimating clusters..\")\n",
    "    frame_with_durations_outliers_removed['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed[['pickup_latitude', 'pickup_longitude']])\n",
    "    #frame_with_durations_outliers_removed_2016['pickup_cluster'] = kmeans.predict(frame_with_durations_outliers_removed_2016[['pickup_latitude', 'pickup_longitude']])\n",
    "\n",
    "    print (\"Final groupbying..\")\n",
    "    final_updated_frame = add_pickup_bins(frame_with_durations_outliers_removed,month_no,year_no)\n",
    "    final_groupby_frame = final_updated_frame[['pickup_cluster','pickup_bins','trip_distance']].groupby(['pickup_cluster','pickup_bins']).count()\n",
    "    \n",
    "    return final_updated_frame,final_groupby_frame\n",
    "    \n",
    "month_jan_2016 = dd.read_csv('yellow_tripdata_2016-01.csv')\n",
    "month_feb_2016 = dd.read_csv('yellow_tripdata_2016-02.csv')\n",
    "month_mar_2016 = dd.read_csv('yellow_tripdata_2016-03.csv')\n",
    "\n",
    "jan_2016_frame,jan_2016_groupby = datapreparation(month_jan_2016,kmeans,1,2016)\n",
    "feb_2016_frame,feb_2016_groupby = datapreparation(month_feb_2016,kmeans,2,2016)\n",
    "mar_2016_frame,mar_2016_groupby = datapreparation(month_mar_2016,kmeans,3,2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HEW9vuBwpYUc"
   },
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUMSCEHEpYUd"
   },
   "outputs": [],
   "source": [
    "# Gets the unique bins where pickup values are present for each each reigion\n",
    "\n",
    "# for each cluster region we will collect all the indices of 10min intravels in which the pickups are happened\n",
    "# we got an observation that there are some pickpbins that doesnt have any pickups\n",
    "def return_unq_pickup_bins(frame):\n",
    "    values = []\n",
    "    for i in range(0,30):\n",
    "        new = frame[frame['pickup_cluster'] == i]\n",
    "        list_unq = list(set(new['pickup_bins']))\n",
    "        list_unq.sort()\n",
    "        values.append(list_unq)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeYcUCUxpYUf"
   },
   "outputs": [],
   "source": [
    "# for every month we get all indices of 10min intravels in which atleast one pickup got happened\n",
    "\n",
    "#jan\n",
    "jan_2015_unique = return_unq_pickup_bins(jan_2015_frame)\n",
    "jan_2016_unique = return_unq_pickup_bins(jan_2016_frame)\n",
    "\n",
    "#feb\n",
    "feb_2016_unique = return_unq_pickup_bins(feb_2016_frame)\n",
    "\n",
    "#march\n",
    "mar_2016_unique = return_unq_pickup_bins(mar_2016_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Ocy5bDipYUj"
   },
   "source": [
    "there are two ways to fill up these values\n",
    "<ul>\n",
    "<li> Fill the missing value with 0's</li>\n",
    "<li> Fill the missing values with the avg values\n",
    "<ul>\n",
    "<li> Case 1:(values missing at the start)  <br>Ex1: \\_ \\_ \\_ x =>ceil(x/4), ceil(x/4), ceil(x/4), ceil(x/4) <br> Ex2: \\_ \\_ x => ceil(x/3), ceil(x/3), ceil(x/3) </li>\n",
    "<li> Case 2:(values missing in middle) <br>Ex1: x \\_ \\_ y => ceil((x+y)/4), ceil((x+y)/4), ceil((x+y)/4), ceil((x+y)/4) <br> Ex2: x \\_ \\_ \\_ y => ceil((x+y)/5), ceil((x+y)/5), ceil((x+y)/5), ceil((x+y)/5), ceil((x+y)/5) </li>\n",
    "<li> Case 3:(values missing at the end)  <br>Ex1: x \\_ \\_ \\_  => ceil(x/4), ceil(x/4), ceil(x/4), ceil(x/4) <br> Ex2: x \\_  => ceil(x/2), ceil(x/2) </li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B84diUuKpYUj"
   },
   "outputs": [],
   "source": [
    "# Fills a value of zero for every bin where no pickup data is present \n",
    "# the count_values: number pickps that are happened in each region for each 10min intravel\n",
    "# there wont be any value if there are no picksups.\n",
    "# values: number of unique bins\n",
    "\n",
    "# for every 10min intravel(pickup_bin) we will check it is there in our unique bin,\n",
    "# if it is there we will add the count_values[index] to smoothed data\n",
    "# if not we add 0 to the smoothed data\n",
    "# we finally return smoothed data\n",
    "def fill_missing(count_values,values):\n",
    "    smoothed_regions=[]\n",
    "    ind=0\n",
    "    for r in range(0,30):\n",
    "        smoothed_bins=[]\n",
    "        for i in range(4464):\n",
    "            if i in values[r]:\n",
    "                smoothed_bins.append(count_values[ind])\n",
    "                ind+=1\n",
    "            else:\n",
    "                smoothed_bins.append(0)\n",
    "        smoothed_regions.extend(smoothed_bins)\n",
    "    return smoothed_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtwtQnhQpYUl"
   },
   "outputs": [],
   "source": [
    "# Fills a value of zero for every bin where no pickup data is present \n",
    "# the count_values: number pickps that are happened in each region for each 10min intravel\n",
    "# there wont be any value if there are no picksups.\n",
    "# values: number of unique bins\n",
    "\n",
    "# for every 10min intravel(pickup_bin) we will check it is there in our unique bin,\n",
    "# if it is there we will add the count_values[index] to smoothed data\n",
    "# if not we add smoothed data (which is calculated based on the methods that are discussed in the above markdown cell)\n",
    "# we finally return smoothed data\n",
    "def smoothing(count_values,values):\n",
    "    smoothed_regions=[] # stores list of final smoothed values of each reigion\n",
    "    ind=0\n",
    "    repeat=0 \n",
    "    smoothed_value=0\n",
    "    for r in range(0,30):\n",
    "        smoothed_bins=[] #stores the final smoothed values\n",
    "        repeat=0\n",
    "        for i in range(4464):\n",
    "            if repeat!=0: # prevents iteration for a value which is already visited/resolved\n",
    "                repeat-=1\n",
    "                continue\n",
    "            if i in values[r]: #checks if the pickup-bin exists \n",
    "                smoothed_bins.append(count_values[ind]) # appends the value of the pickup bin if it exists\n",
    "            else:\n",
    "                if i!=0:\n",
    "                    right_hand_limit=0\n",
    "                    for j in range(i,4464):\n",
    "                        if  j not in values[r]: #searches for the left-limit or the pickup-bin value which has a pickup value\n",
    "                            continue\n",
    "                        else:\n",
    "                            right_hand_limit=j\n",
    "                            break\n",
    "                    if right_hand_limit==0:\n",
    "                    #Case 1: When we have the last/last few values are found to be missing,hence we have no right-limit here\n",
    "                        smoothed_value=count_values[ind-1]*1.0/((4463-i)+2)*1.0                               \n",
    "                        for j in range(i,4464):                              \n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                        smoothed_bins[i-1] = math.ceil(smoothed_value)\n",
    "                        repeat=(4463-i)\n",
    "                        ind-=1\n",
    "                    else:\n",
    "                    #Case 2: When we have the missing values between two known values\n",
    "                        smoothed_value=(count_values[ind-1]+count_values[ind])*1.0/((right_hand_limit-i)+2)*1.0             \n",
    "                        for j in range(i,right_hand_limit+1):\n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                        smoothed_bins[i-1] = math.ceil(smoothed_value)\n",
    "                        repeat=(right_hand_limit-i)\n",
    "                else:\n",
    "                    #Case 3: When we have the first/first few values are found to be missing,hence we have no left-limit here\n",
    "                    right_hand_limit=0\n",
    "                    for j in range(i,4464):\n",
    "                        if  j not in values[r]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            right_hand_limit=j\n",
    "                            break\n",
    "                    smoothed_value=count_values[ind]*1.0/((right_hand_limit-i)+1)*1.0\n",
    "                    for j in range(i,right_hand_limit+1):\n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                    repeat=(right_hand_limit-i)\n",
    "            ind+=1\n",
    "        smoothed_regions.extend(smoothed_bins)\n",
    "    return smoothed_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHGsXfb0pYUz"
   },
   "outputs": [],
   "source": [
    "# Jan-2015 data is smoothed, Jan,Feb & March 2016 data missing values are filled with zero\n",
    "jan_2015_smooth = smoothing(jan_2015_groupby['trip_distance'].values,jan_2015_unique)\n",
    "jan_2016_smooth = fill_missing(jan_2016_groupby['trip_distance'].values,jan_2016_unique)\n",
    "feb_2016_smooth = fill_missing(feb_2016_groupby['trip_distance'].values,feb_2016_unique)\n",
    "mar_2016_smooth = fill_missing(mar_2016_groupby['trip_distance'].values,mar_2016_unique)\n",
    "\n",
    "# Making list of all the values of pickup data in every bin for a period of 3 months and storing them region-wise \n",
    "regions_cum = []\n",
    "\n",
    "# a =[1,2,3]\n",
    "# b = [2,3,4]\n",
    "# a+b = [1, 2, 3, 2, 3, 4]\n",
    "\n",
    "# number of 10min indices for jan 2015= 24*31*60/10 = 4464\n",
    "# number of 10min indices for jan 2016 = 24*31*60/10 = 4464\n",
    "# number of 10min indices for feb 2016 = 24*29*60/10 = 4176\n",
    "# number of 10min indices for march 2016 = 24*31*60/10 = 4464\n",
    "# regions_cum: it will contain 40 lists, each list will contain 4464+4176+4464 values which represents the number of pickups \n",
    "# that are happened for three months in 2016 data\n",
    "\n",
    "for i in range(0,30):\n",
    "    regions_cum.append(jan_2016_smooth[4464*i:4464*(i+1)]+feb_2016_smooth[4176*i:4176*(i+1)]+mar_2016_smooth[4464*i:4464*(i+1)])\n",
    "\n",
    "# print(len(regions_cum))\n",
    "# 30\n",
    "# print(len(regions_cum[0]))\n",
    "# 13104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XnipIdfYpYU0"
   },
   "source": [
    "## Time series and Fourier Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kd-fYydL2yDy"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "76vu5IXCpYU8",
    "outputId": "0f150ac9-1a35-4f18-8089-f4a7fb38dbb7",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEKCAYAAADEovgeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWeacbMzMLHNONmZmljknGzMzy9z/B/AwDxQojFh4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# getting peaks: https://blog.ytotech.com/2015/11/01/findpeaks-in-python/\n",
    "# read more about fft function : https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fft.html\n",
    "Y    = np.fft.fft(np.array(jan_2016_smooth)[0:4460])\n",
    "# read more about the fftfreq: https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fftfreq.html  \n",
    "freq = np.fft.fftfreq(4460, 1)\n",
    "n = len(freq)\n",
    "plt.figure()\n",
    "plt.plot( freq[:int(n/2)], np.abs(Y)[:int(n/2)] )\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Nxl7fcRl2-ch",
    "outputId": "a473faa8-5084-4209-e768-42607ea3b1c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>amp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>722007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.006951</td>\n",
       "      <td>246726.577980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>0.013901</td>\n",
       "      <td>78143.938628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.013901</td>\n",
       "      <td>78143.938628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>0.013004</td>\n",
       "      <td>55749.451715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq            amp\n",
       "0     0.000000  722007.000000\n",
       "31    0.006951  246726.577980\n",
       "4398  0.013901   78143.938628\n",
       "62    0.013901   78143.938628\n",
       "4402  0.013004   55749.451715"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_amp_df = pd.DataFrame(np.array([np.abs(np.real(freq)), np.abs(Y)]).T, columns=['freq', 'amp'])\n",
    "freq_amp_df.drop_duplicates(inplace=True)\n",
    "freq_amp_df.sort_values('amp', ascending=False, inplace=True)\n",
    "freq_amp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "u-dsDc309PFi",
    "outputId": "8352c89d-7a83-48e8-8ed7-57b04038c2e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          freq            amp\n",
      "0     0.000000  722007.000000\n",
      "31    0.006951  246726.577980\n",
      "4398  0.013901   78143.938628\n",
      "62    0.013901   78143.938628\n",
      "4402  0.013004   55749.451715\n"
     ]
    }
   ],
   "source": [
    "freq_amp_df = freq_amp_df.head()\n",
    "print(freq_amp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Fourier data for every 10-min interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3bi10adf56tj"
   },
   "source": [
    "**For each 10-min interval I take prev 7 days data = 1000 rows (~10080 minutes) and find fft values to add fourier features at that 10-min interval. I will take top 5 frequencies and amplitudes and add them to the matrix. So my final `fft_data` matrix size will be 30 \\* DF(13104 \\* 10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jryKe5-U-6b9",
    "outputId": "ac1dc991-3ff9-4267-efda-c77b94945775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['freq_0', 'amp_0', 'freq_1', 'amp_1', 'freq_2', 'amp_2', 'freq_3', 'amp_3', 'freq_4', 'amp_4']\n"
     ]
    }
   ],
   "source": [
    "freq_amp_cols = []\n",
    "for i in range(5):\n",
    "  freq_amp_cols.append('freq_'+str(i))\n",
    "  freq_amp_cols.append('amp_'+str(i))\n",
    "\n",
    "print(freq_amp_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "4QZrHcSq5jHE",
    "outputId": "efbd0884-c092-48cd-a470-2d7d60728fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0 started..\n",
      "cluster 0 ended..\n",
      "cluster 1 started..\n",
      "cluster 1 ended..\n",
      "cluster 2 started..\n",
      "cluster 2 ended..\n",
      "cluster 3 started..\n",
      "cluster 3 ended..\n",
      "cluster 4 started..\n",
      "cluster 4 ended..\n",
      "cluster 5 started..\n",
      "cluster 5 ended..\n",
      "cluster 6 started..\n",
      "cluster 6 ended..\n",
      "cluster 7 started..\n",
      "cluster 7 ended..\n",
      "cluster 8 started..\n",
      "cluster 8 ended..\n",
      "cluster 9 started..\n",
      "cluster 9 ended..\n",
      "cluster 10 started..\n",
      "cluster 10 ended..\n",
      "cluster 11 started..\n",
      "cluster 11 ended..\n",
      "cluster 12 started..\n",
      "cluster 12 ended..\n",
      "cluster 13 started..\n",
      "cluster 13 ended..\n",
      "cluster 14 started..\n",
      "cluster 14 ended..\n",
      "cluster 15 started..\n",
      "cluster 15 ended..\n",
      "cluster 16 started..\n",
      "cluster 16 ended..\n",
      "cluster 17 started..\n",
      "cluster 17 ended..\n",
      "cluster 18 started..\n",
      "cluster 18 ended..\n",
      "cluster 19 started..\n",
      "cluster 19 ended..\n",
      "cluster 20 started..\n",
      "cluster 20 ended..\n",
      "cluster 21 started..\n",
      "cluster 21 ended..\n",
      "cluster 22 started..\n",
      "cluster 22 ended..\n",
      "cluster 23 started..\n",
      "cluster 23 ended..\n",
      "cluster 24 started..\n",
      "cluster 24 ended..\n",
      "cluster 25 started..\n",
      "cluster 25 ended..\n",
      "cluster 26 started..\n",
      "cluster 26 ended..\n",
      "cluster 27 started..\n",
      "cluster 27 ended..\n",
      "cluster 28 started..\n",
      "cluster 28 ended..\n",
      "cluster 29 started..\n",
      "cluster 29 ended..\n"
     ]
    }
   ],
   "source": [
    "fft_data = []\n",
    "ind = 0\n",
    "for reg in regions_cum:\n",
    "  print(f'cluster {ind} started..')\n",
    "  fft_data_reg = pd.DataFrame(columns = freq_amp_cols)\n",
    "  fft_data_reg.loc[0] = [0]*10\n",
    "  for i in range(1, 13104):\n",
    "    left_ind = max(0, i-1000)\n",
    "    Y    = np.fft.fft(np.array(reg)[left_ind:i])\n",
    "    freq = np.fft.fftfreq(len(Y), 1)\n",
    "    freq_amp_df = pd.DataFrame(np.array([np.abs(np.real(freq)), np.abs(Y)]).T, columns=['freq', 'amp'])\n",
    "    freq_amp_df.drop_duplicates(inplace=True)\n",
    "    freq_amp_df.sort_values('amp', ascending=False, inplace=True)\n",
    "    freq_amp_df = freq_amp_df.head()\n",
    "    freq_amp_df = freq_amp_df.values.flatten()\n",
    "    if len(freq_amp_df)<10:\n",
    "      extra_zeros = [0]*(10-len(freq_amp_df))\n",
    "      freq_amp_df = np.append(freq_amp_df, [extra_zeros])\n",
    "    fft_data_reg.loc[i] = freq_amp_df\n",
    "  fft_data.append(fft_data_reg)\n",
    "  print(f'cluster {ind} ended..')\n",
    "  ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3m01xiQajTB4",
    "outputId": "478bd731-82fc-4b00-e118-37895970b995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "(13104, 10)\n"
     ]
    }
   ],
   "source": [
    "print(len(fft_data))\n",
    "print(fft_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9iVFeu0pYU-"
   },
   "outputs": [],
   "source": [
    "#Preparing the Dataframe only with x(i) values as jan-2015 data and y(i) values as jan-2016\n",
    "ratios_jan = pd.DataFrame()\n",
    "ratios_jan['Given']=jan_2015_smooth\n",
    "ratios_jan['Prediction']=jan_2016_smooth\n",
    "ratios_jan['Ratios']=ratios_jan['Prediction']*1.0/ratios_jan['Given']*1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YORIMx7LlO8Y"
   },
   "source": [
    "**Not Running baseline models except exponential weighted average because it is used in the final model and not using ratios in the final model as they are not providing as good results as previous day`s values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eoV1TT2qpYVa"
   },
   "source": [
    "## Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eN4agQdupYVb"
   },
   "source": [
    "### Train-Test Split\n",
    "Before we start predictions using the tree based regression models we take 3 months of 2016 pickup data and split it such that for every region we have 70% data in train and 30% in test, ordered date-wise for every region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wiVsOBxYpYVb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preparing data to be split into train and test, The below prepares data in cumulative form which will be later split into test and train\n",
    "# number of 10min indices for jan 2015= 24*31*60/10 = 4464\n",
    "# number of 10min indices for jan 2016 = 24*31*60/10 = 4464\n",
    "# number of 10min indices for feb 2016 = 24*29*60/10 = 4176\n",
    "# number of 10min indices for march 2016 = 24*31*60/10 = 4464\n",
    "# regions_cum: it will contain 40 lists, each list will contain 4464+4176+4464 values which represents the number of pickups \n",
    "# that are happened for three months in 2016 data\n",
    "\n",
    "# print(len(regions_cum))\n",
    "# 40\n",
    "# print(len(regions_cum[0]))\n",
    "# 12960\n",
    "\n",
    "# we take number of pickups that are happened in last 5 10min intravels\n",
    "number_of_time_stamps = 5\n",
    "\n",
    "# output varaible\n",
    "# it is list of lists\n",
    "# it will contain number of pickups 13099 for each cluster\n",
    "output = []\n",
    "\n",
    "\n",
    "# tsne_lat will contain 13104-5=13099 times lattitude of cluster center for every cluster\n",
    "# Ex: [[cent_lat 13099times],[cent_lat 13099times], [cent_lat 13099times].... 40 lists]\n",
    "# it is list of lists\n",
    "tsne_lat = []\n",
    "\n",
    "\n",
    "# tsne_lon will contain 13104-5=13099 times logitude of cluster center for every cluster\n",
    "# Ex: [[cent_long 13099times],[cent_long 13099times], [cent_long 13099times].... 40 lists]\n",
    "# it is list of lists\n",
    "tsne_lon = []\n",
    "\n",
    "# we will code each day \n",
    "# sunday = 0, monday=1, tue = 2, wed=3, thur=4, fri=5,sat=6\n",
    "# for every cluster we will be adding 13099 values, each value represent to which day of the week that pickup bin belongs to\n",
    "# it is list of lists\n",
    "tsne_weekday = []\n",
    "\n",
    "# its an numbpy array, of shape (523960, 5)\n",
    "# each row corresponds to an entry in out data\n",
    "# for the first row we will have [f0,f1,f2,f3,f4] fi=number of pickups happened in i+1th 10min intravel(bin)\n",
    "# the second row will have [f1,f2,f3,f4,f5]\n",
    "# the third row will have [f2,f3,f4,f5,f6]\n",
    "# and so on...\n",
    "tsne_feature = []\n",
    "\n",
    "\n",
    "tsne_feature = [0]*number_of_time_stamps\n",
    "for i in range(0,30):\n",
    "    tsne_lat.append([kmeans.cluster_centers_[i][0]]*13099)\n",
    "    tsne_lon.append([kmeans.cluster_centers_[i][1]]*13099)\n",
    "    # jan 1st 2016 is thursday, so we start our day from 4: \"(int(k/144))%7+4\"\n",
    "    # our prediction start from 5th 10min intravel since we need to have number of pickups that are happened in last 5 pickup bins\n",
    "    tsne_weekday.append([int(((int(k/144))%7+4)%7) for k in range(5,4464+4176+4464)])\n",
    "    # regions_cum is a list of lists [[x1,x2,x3..x13104], [x1,x2,x3..x13104], [x1,x2,x3..x13104], [x1,x2,x3..x13104], [x1,x2,x3..x13104], .. 40 lsits]\n",
    "    tsne_feature = np.vstack((tsne_feature, [regions_cum[i][r:r+number_of_time_stamps] for r in range(0,len(regions_cum[i])-number_of_time_stamps)]))\n",
    "    output.append(regions_cum[i][5:])\n",
    "tsne_feature = tsne_feature[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HMv1rC51pYVc",
    "outputId": "1546041d-1de5-45e2-baa0-0556993ee2ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tsne_lat[0])*len(tsne_lat) == tsne_feature.shape[0] == len(tsne_weekday)*len(tsne_weekday[0]) == 30*13099 == len(output)*len(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exponential moving averages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ofQ8zCtgpYVe"
   },
   "outputs": [],
   "source": [
    "# Getting the predictions of exponential moving averages to be used as a feature in cumulative form\n",
    "\n",
    "# upto now we computed 8 features for every data point that starts from 50th min of the day\n",
    "# 1. cluster center lattitude\n",
    "# 2. cluster center longitude\n",
    "# 3. day of the week \n",
    "# 4. f_t_1: number of pickups that are happened previous t-1th 10min intravel\n",
    "# 5. f_t_2: number of pickups that are happened previous t-2th 10min intravel\n",
    "# 6. f_t_3: number of pickups that are happened previous t-3th 10min intravel\n",
    "# 7. f_t_4: number of pickups that are happened previous t-4th 10min intravel\n",
    "# 8. f_t_5: number of pickups that are happened previous t-5th 10min intravel\n",
    "\n",
    "# from the baseline models we said the exponential weighted moving avarage gives us the best error\n",
    "# we will try to add the same exponential weighted moving avarage at t as a feature to our data\n",
    "# exponential weighted moving avarage => p'(t) = alpha*p'(t-1) + (1-alpha)*P(t-1) \n",
    "alpha=0.3\n",
    "\n",
    "# it is a temporary array that store exponential weighted moving avarage for each 10min intravel, \n",
    "# for each cluster it will get reset\n",
    "# for every cluster it contains 13104 values\n",
    "predicted_values=[]\n",
    "\n",
    "# it is similar like tsne_lat\n",
    "# it is list of lists\n",
    "# predict_list is a list of lists [[x5,x6,x7..x13104], [x5,x6,x7..x13104], [x5,x6,x7..x13104], [x5,x6,x7..x13104], [x5,x6,x7..x13104], .. 40 lsits]\n",
    "predict_list = []\n",
    "tsne_flat_exp_avg = []\n",
    "for r in range(0,30):\n",
    "    for i in range(0,13104):\n",
    "        if i==0:\n",
    "            predicted_value= regions_cum[r][0]\n",
    "            predicted_values.append(0)\n",
    "            continue\n",
    "        predicted_values.append(predicted_value)\n",
    "        predicted_value =int((alpha*predicted_value) + (1-alpha)*(regions_cum[r][i]))\n",
    "    predict_list.append(predicted_values[5:])\n",
    "    predicted_values=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OvIFa9-PpYVf",
    "outputId": "9917b270-251c-45f8-c8f5-988df4fd3695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "(13099, 10)\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "  fft_data[i] = fft_data[i][5:]\n",
    "print(len(fft_data))\n",
    "print(fft_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "31AvW-MApYVf",
    "outputId": "293f10aa-f728-45dd-b5e9-ad9261347091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train data : 9169\n",
      "size of test data : 3929\n"
     ]
    }
   ],
   "source": [
    "# train, test split : 70% 30% split\n",
    "# Before we start predictions using the tree based regression models we take 3 months of 2016 pickup data \n",
    "# and split it such that for every region we have 70% data in train and 30% in test,\n",
    "# ordered date-wise for every region\n",
    "print(\"size of train data :\", int(13099*0.7))\n",
    "print(\"size of test data :\", int(13099*0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ty3ywNTepYVh"
   },
   "outputs": [],
   "source": [
    "# extracting first 9169 timestamp values i.e 70% of 13099 (total timestamps) for our training data\n",
    "train_features =  [tsne_feature[i*13099:(13099*i+9169)] for i in range(0,30)]\n",
    "# temp = [0]*(12955 - 9068)\n",
    "test_features = [tsne_feature[(13099*(i))+9169:13099*(i+1)] for i in range(0,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9T0p_qhipYVi",
    "outputId": "e63abf3e-8dff-447c-af2c-0fd5f5fda8cc",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data clusters 30 Number of data points in trian data 9169 Each data point contains 5 features\n",
      "Number of data clusters 30 Number of data points in test data 3930 Each data point contains 5 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data clusters\",len(train_features), \"Number of data points in trian data\", len(train_features[0]), \"Each data point contains\", len(train_features[0][0]),\"features\")\n",
    "print(\"Number of data clusters\",len(train_features), \"Number of data points in test data\", len(test_features[0]), \"Each data point contains\", len(test_features[0][0]),\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUrc4FPepYVk"
   },
   "outputs": [],
   "source": [
    "# extracting first 9169 timestamp values i.e 70% of 13099 (total timestamps) for our training data\n",
    "tsne_train_flat_lat = [i[:9169] for i in tsne_lat]\n",
    "tsne_train_flat_lon = [i[:9169] for i in tsne_lon]\n",
    "tsne_train_flat_weekday = [i[:9169] for i in tsne_weekday]\n",
    "tsne_train_flat_output = [i[:9169] for i in output]\n",
    "tsne_train_flat_exp_avg = [i[:9169] for i in predict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJ4h3S58pYVl"
   },
   "outputs": [],
   "source": [
    "# extracting the rest of the timestamp values i.e 30% of 12956 (total timestamps) for our test data\n",
    "tsne_test_flat_lat = [i[9169:] for i in tsne_lat]\n",
    "tsne_test_flat_lon = [i[9169:] for i in tsne_lon]\n",
    "tsne_test_flat_weekday = [i[9169:] for i in tsne_weekday]\n",
    "tsne_test_flat_output = [i[9169:] for i in output]\n",
    "tsne_test_flat_exp_avg = [i[9169:] for i in predict_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNmxi1aYq-aZ"
   },
   "outputs": [],
   "source": [
    "fft_train_data = [i[:9169] for i in fft_data]\n",
    "fft_test_data = [i[9169:] for i in fft_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3_aVVZnpYVm"
   },
   "outputs": [],
   "source": [
    "# the above contains values in the form of list of lists (i.e. list of values of each region), here we make all of them in one list\n",
    "train_new_features = []\n",
    "for i in range(0,30):\n",
    "    train_new_features.extend(train_features[i])\n",
    "test_new_features = []\n",
    "for i in range(0,30):\n",
    "    test_new_features.extend(test_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0ZhxsHI9sDlB",
    "outputId": "253ba0b1-841b-4d82-d51b-99294a9d51e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275070, 10)\n",
      "(117900, 10)\n"
     ]
    }
   ],
   "source": [
    "fft_train_data = pd.concat(fft_train_data, ignore_index=True)\n",
    "fft_test_data = pd.concat(fft_test_data, ignore_index=True)\n",
    "print(fft_train_data.shape)\n",
    "print(fft_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CacNoTj8pYVo"
   },
   "outputs": [],
   "source": [
    "# converting lists of lists into sinle list i.e flatten\n",
    "# a  = [[1,2,3,4],[4,6,7,8]]\n",
    "# print(sum(a,[]))\n",
    "# [1, 2, 3, 4, 4, 6, 7, 8]\n",
    "\n",
    "tsne_train_lat = sum(tsne_train_flat_lat, [])\n",
    "tsne_train_lon = sum(tsne_train_flat_lon, [])\n",
    "tsne_train_weekday = sum(tsne_train_flat_weekday, [])\n",
    "tsne_train_output = sum(tsne_train_flat_output, [])\n",
    "tsne_train_exp_avg = sum(tsne_train_flat_exp_avg,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vAHbGnkopYVs"
   },
   "outputs": [],
   "source": [
    "# converting lists of lists into sinle list i.e flatten\n",
    "# a  = [[1,2,3,4],[4,6,7,8]]\n",
    "# print(sum(a,[]))\n",
    "# [1, 2, 3, 4, 4, 6, 7, 8]\n",
    "\n",
    "tsne_test_lat = sum(tsne_test_flat_lat, [])\n",
    "tsne_test_lon = sum(tsne_test_flat_lon, [])\n",
    "tsne_test_weekday = sum(tsne_test_flat_weekday, [])\n",
    "tsne_test_output = sum(tsne_test_flat_output, [])\n",
    "tsne_test_exp_avg = sum(tsne_test_flat_exp_avg,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6d-0xxZPuxJm",
    "outputId": "098fc043-3dbb-4a14-f1b0-7658d643d9be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275070"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['ft_5','ft_4','ft_3','ft_2','ft_1']\n",
    "df_train = pd.DataFrame(data=train_new_features, columns=columns)\n",
    "sum(df_train.index == fft_train_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMWj_5GOwfDA"
   },
   "outputs": [],
   "source": [
    "df_train_clusters = np.array([[i]*9169 for i in range(30)]).flatten()\n",
    "df_test_clusters = np.array([[i]*3930 for i in range(30)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j5ND-T1apYVt",
    "outputId": "62043b5f-e33f-4035-f64c-e43eeddb4833"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275070, 20)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the data frame for our train data\n",
    "columns = ['ft_5','ft_4','ft_3','ft_2','ft_1']\n",
    "df_train = pd.DataFrame(data=train_new_features, columns=columns)\n",
    "df_train = pd.concat([df_train, fft_train_data], axis=1)\n",
    "df_train['lat'] = tsne_train_lat\n",
    "df_train['lon'] = tsne_train_lon\n",
    "df_train['weekday'] = tsne_train_weekday\n",
    "df_train['exp_avg'] = tsne_train_exp_avg\n",
    "df_train['cluster_id'] = df_train_clusters\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aa8LZ28GpYVw",
    "outputId": "bdad8ce7-1941-4869-e267-255a09b91c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117900, 20)\n"
     ]
    }
   ],
   "source": [
    "# Preparing the data frame for our train data\n",
    "df_test = pd.DataFrame(data=test_new_features, columns=columns)\n",
    "df_test = pd.concat([df_test, fft_test_data], axis=1)\n",
    "df_test['lat'] = tsne_test_lat\n",
    "df_test['lon'] = tsne_test_lon\n",
    "df_test['weekday'] = tsne_test_weekday\n",
    "df_test['exp_avg'] = tsne_test_exp_avg\n",
    "df_test['cluster_id'] = df_test_clusters\n",
    "\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "eQj1LfMnpYVx",
    "outputId": "126361f3-b8dc-4c04-d9ac-f2b082c7a1d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ft_5</th>\n",
       "      <th>ft_4</th>\n",
       "      <th>ft_3</th>\n",
       "      <th>ft_2</th>\n",
       "      <th>ft_1</th>\n",
       "      <th>freq_0</th>\n",
       "      <th>amp_0</th>\n",
       "      <th>freq_1</th>\n",
       "      <th>amp_1</th>\n",
       "      <th>freq_2</th>\n",
       "      <th>amp_2</th>\n",
       "      <th>freq_3</th>\n",
       "      <th>amp_3</th>\n",
       "      <th>freq_4</th>\n",
       "      <th>amp_4</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>weekday</th>\n",
       "      <th>exp_avg</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>271</td>\n",
       "      <td>270</td>\n",
       "      <td>238</td>\n",
       "      <td>269</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>178108</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64807.8</td>\n",
       "      <td>0.014</td>\n",
       "      <td>24480.6</td>\n",
       "      <td>0.014</td>\n",
       "      <td>24480.6</td>\n",
       "      <td>0.021</td>\n",
       "      <td>16455.5</td>\n",
       "      <td>40.777809</td>\n",
       "      <td>-73.954054</td>\n",
       "      <td>4</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270</td>\n",
       "      <td>238</td>\n",
       "      <td>269</td>\n",
       "      <td>260</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>178150</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64845.1</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64845.1</td>\n",
       "      <td>0.014</td>\n",
       "      <td>24469</td>\n",
       "      <td>0.021</td>\n",
       "      <td>16418.3</td>\n",
       "      <td>40.777809</td>\n",
       "      <td>-73.954054</td>\n",
       "      <td>4</td>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>238</td>\n",
       "      <td>269</td>\n",
       "      <td>260</td>\n",
       "      <td>281</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>178190</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64881.4</td>\n",
       "      <td>0.014</td>\n",
       "      <td>24454.6</td>\n",
       "      <td>0.021</td>\n",
       "      <td>16380.7</td>\n",
       "      <td>0.001</td>\n",
       "      <td>14849.1</td>\n",
       "      <td>40.777809</td>\n",
       "      <td>-73.954054</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>269</td>\n",
       "      <td>260</td>\n",
       "      <td>281</td>\n",
       "      <td>264</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>178228</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64916.5</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64916.5</td>\n",
       "      <td>0.014</td>\n",
       "      <td>24437.9</td>\n",
       "      <td>0.021</td>\n",
       "      <td>16343.7</td>\n",
       "      <td>40.777809</td>\n",
       "      <td>-73.954054</td>\n",
       "      <td>4</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>281</td>\n",
       "      <td>264</td>\n",
       "      <td>286</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>178249</td>\n",
       "      <td>0.007</td>\n",
       "      <td>64936.3</td>\n",
       "      <td>0.014</td>\n",
       "      <td>24427.1</td>\n",
       "      <td>0.021</td>\n",
       "      <td>16322.7</td>\n",
       "      <td>0.021</td>\n",
       "      <td>16322.7</td>\n",
       "      <td>40.777809</td>\n",
       "      <td>-73.954054</td>\n",
       "      <td>4</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ft_5  ft_4  ft_3  ft_2  ...        lon weekday exp_avg cluster_id\n",
       "0   271   270   238   269  ... -73.954054       4     260          0\n",
       "1   270   238   269   260  ... -73.954054       4     274          0\n",
       "2   238   269   260   281  ... -73.954054       4     267          0\n",
       "3   269   260   281   264  ... -73.954054       4     280          0\n",
       "4   260   281   264   286  ... -73.954054       4     280          0\n",
       "\n",
       "[5 rows x 20 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2tvbI-GkpYWF"
   },
   "source": [
    "# Assignments\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JvEcs6bfpYWG",
    "outputId": "23ce918c-7ffb-4dd6-8aa5-f367fc1eb9ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTask 1: Incorporate Fourier features as features into Regression models and measure MAPE. <br>\\n\\nTask 2: Perform hyper-parameter tuning for Regression models.\\n        2a. Linear Regression: Grid Search\\n        2b. Random Forest: Random Search \\n        2c. Xgboost: Random Search\\nTask 3: Explore more time-series features using Google search/Quora/Stackoverflow\\nto reduce the MAPE to < 12%\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Task 1: Incorporate Fourier features as features into Regression models and measure MAPE. <br>\n",
    "\n",
    "Task 2: Perform hyper-parameter tuning for Regression models.\n",
    "        2a. Linear Regression: Grid Search\n",
    "        2b. Random Forest: Random Search \n",
    "        2c. Xgboost: Random Search\n",
    "Task 3: Explore more time-series features using Google search/Quora/Stackoverflow\n",
    "to reduce the MAPE to < 12%\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As fourier features are included in data in above code blocks, we can go ahead and do second Task.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rykiaxYlpYVz"
   },
   "source": [
    "### Using Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITaFg0YmyAb4"
   },
   "source": [
    "**Before Running linear regression we can see some columns are not linearly related to the output values. Those are cluster_id, weekday, and even latitude and longitude. So it makes sense to encode them before running. We can remove latitude, longitude and cluster id and replace them with one-hot encoding of cluster id. And we can onehot encode the weekday column as well. As our model is Linear regression we can have more dimensions which will not affect our performance. For other tree based models we can neglect encoding for such features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w68YkR3GzS7e"
   },
   "source": [
    "**Creating new dataframe for training linear regression and adding onehot encoded data into it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkOYJO-yzSLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HTfwIe2V1Fu4",
    "outputId": "0e4924f0-00b2-42fd-ddf3-5bdfa9300f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "onehotcoder = OneHotEncoder()\n",
    "onehotcoder.fit(df_train[['weekday', 'cluster_id']])\n",
    "# should be 30+7 = 37\n",
    "print(len(onehotcoder.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lyx0VdYS18i_"
   },
   "outputs": [],
   "source": [
    "df_ohe_train = onehotcoder.transform(df_train[['weekday', 'cluster_id']])\n",
    "df_ohe_test = onehotcoder.transform(df_test[['weekday', 'cluster_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6tvZQ6Q54XNm"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dEOwpwId5mv8"
   },
   "outputs": [],
   "source": [
    "for i in df_train.columns:\n",
    "  df_train[i] = pd.to_numeric(df_train[i])\n",
    "  df_test[i] = pd.to_numeric(df_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "cj_c66Xo2UU2",
    "outputId": "296c9685-9694-4607-a555-2b366ef66258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275070, 53)\n",
      "(117900, 53)\n"
     ]
    }
   ],
   "source": [
    "df_lr_train = df_train.drop(['weekday', 'lat', 'lon', 'cluster_id'], axis=1)\n",
    "df_lr_test = df_test.drop(['weekday', 'lat', 'lon', 'cluster_id'], axis=1)\n",
    "\n",
    "df_lr_train = sparse.hstack([df_lr_train.values, df_ohe_train])\n",
    "df_lr_test = sparse.hstack([df_lr_test.values, df_ohe_test])\n",
    "# number of columns = 20-4+37 = 53\n",
    "print(df_lr_train.shape)\n",
    "print(df_lr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j39x2twz6dab"
   },
   "outputs": [],
   "source": [
    "def calc_MAPE(y_true, y_predict):\n",
    "  return mean_absolute_error(y_true, y_predict)/(sum(y_true)/len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "a4-FX3CdpYV0",
    "outputId": "1fd70764-60b4-4fba-8029-af0fa3561427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With normalize = False:\n",
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False}\n",
      "train MAPE: 0.12530635199192275\n",
      "test MAPE: 0.11904826253585739\n",
      "\n",
      "\n",
      "With normalize = True:\n",
      "{'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': True}\n",
      "train MAPE: 0.12530635199192275\n",
      "test MAPE: 0.11904826253585739\n"
     ]
    }
   ],
   "source": [
    "# find more about LinearRegression function here http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# -------------------------\n",
    "# default paramters\n",
    "# sklearn.linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=1)\n",
    "\n",
    "# some of methods of LinearRegression()\n",
    "# fit(X, y[, sample_weight])\tFit linear model.\n",
    "# get_params([deep])\tGet parameters for this estimator.\n",
    "# predict(X)\tPredict using the linear model\n",
    "# score(X, y[, sample_weight])\tReturns the coefficient of determination R^2 of the prediction.\n",
    "# set_params(**params)\tSet the parameters of this estimator.\n",
    "# -----------------------\n",
    "# video link: https://www.appliedaicourse.com/course/applied-ai-course-online/lessons/geometric-intuition-1-2-copy-8/\n",
    "# -----------------------\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"With normalize = False:\")\n",
    "lr_reg=LinearRegression()\n",
    "print(lr_reg.get_params())\n",
    "lr_reg.fit(df_train, tsne_train_output)\n",
    "\n",
    "y_pred = lr_reg.predict(df_test)\n",
    "lr_test_predictions = [round(value) for value in y_pred]\n",
    "y_pred = lr_reg.predict(df_train)\n",
    "lr_train_predictions = [round(value) for value in y_pred]\n",
    "\n",
    "print(f'train MAPE: {calc_MAPE(tsne_train_output, lr_train_predictions)}')\n",
    "print(f'test MAPE: {calc_MAPE(tsne_test_output, lr_test_predictions)}')\n",
    "\n",
    "print(\"\\n\\nWith normalize = True:\")\n",
    "lr_reg=LinearRegression(normalize=True)\n",
    "print(lr_reg.get_params())\n",
    "lr_reg.fit(df_train, tsne_train_output)\n",
    "\n",
    "y_pred = lr_reg.predict(df_test)\n",
    "lr_test_predictions = [round(value) for value in y_pred]\n",
    "y_pred = lr_reg.predict(df_train)\n",
    "lr_train_predictions = [round(value) for value in y_pred]\n",
    "\n",
    "print(f'train MAPE: {calc_MAPE(tsne_train_output, lr_train_predictions)}')\n",
    "print(f'test MAPE: {calc_MAPE(tsne_test_output, lr_test_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fyg4lzJf9bP3"
   },
   "source": [
    "**Input for linear regression is changed. The features which are meant to be categorical are changed to onehot encodings, as increase in dimensions is not a problem for linear regression. I didnt find any hyper-parameters for sklearn's LinearRegression .For both \"with normalize\" and \"without normalize\" the MAPE values are same. And the test MAPE value dropped below 12% for this model which is very good.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CbdQSLMipYV1"
   },
   "source": [
    "### Using Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cu_PHwAD_6iE"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "1yH4SyUqpYV1",
    "outputId": "800e4639-7077-4208-f9d6-6f5384359437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators =  10 Train Score 0.054882891508404835 test Score 0.12356400094386034\n",
      "Estimators =  50 Train Score 0.04996592943741556 test Score 0.11817462886896045\n",
      "Estimators =  100 Train Score 0.04933770553814925 test Score 0.11756832532532893\n",
      "Estimators =  175 Train Score 0.04908163876495708 test Score 0.1172080135892906\n",
      "Estimators =  250 Train Score 0.04893984310310891 test Score 0.11714684101278983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Estimators vs score')"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyGFhZmaFHBZmZlbo/wNf8AtKwEkbgQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimators = [10,50,100,175,250]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in estimators:\n",
    "  clf = RandomForestRegressor(n_estimators=i, min_samples_split=4, n_jobs=-1)\n",
    "  clf.fit(df_train, tsne_train_output)\n",
    "  train_sc = calc_MAPE(tsne_train_output,clf.predict(df_train))\n",
    "  test_sc = calc_MAPE(tsne_test_output,clf.predict(df_test))\n",
    "  test_scores.append(test_sc)\n",
    "  train_scores.append(train_sc)\n",
    "  print('Estimators = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
    "plt.plot(estimators,train_scores,label='Train Score')\n",
    "plt.plot(estimators,test_scores,label='Test Score')\n",
    "plt.xlabel('Estimators')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Estimators vs score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "colab_type": "code",
    "id": "OZ-AYmmZCTvt",
    "outputId": "20f55aab-f38c-4026-c38b-3227725f3e04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depths =  3 Train Score 0.16192714763533733 test Score 0.15180177439393988\n",
      "Depths =  5 Train Score 0.12766156602817486 test Score 0.12095851757449985\n",
      "Depths =  10 Train Score 0.12012001274781052 test Score 0.11783028051823466\n",
      "Depths =  20 Train Score 0.09084533224337613 test Score 0.11726011269961327\n",
      "Depths =  50 Train Score 0.04706327217774408 test Score 0.11855205833363403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Depths vs score')"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhIXAoLERGJ6/8DgjUyGcqwwGMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = [3,5,10,20, 50]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in depths:\n",
    "  clf = RandomForestRegressor(n_estimators=40, max_depth=i, n_jobs=-1)\n",
    "  clf.fit(df_train, tsne_train_output)\n",
    "  train_sc = calc_MAPE(tsne_train_output,clf.predict(df_train))\n",
    "  test_sc = calc_MAPE(tsne_test_output,clf.predict(df_test))\n",
    "  test_scores.append(test_sc)\n",
    "  train_scores.append(train_sc)\n",
    "  print('Depths = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
    "plt.plot(depths,train_scores,label='Train Score')\n",
    "plt.plot(depths,test_scores,label='Test Score')\n",
    "plt.xlabel('Depths')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Depths vs score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking `max_depth` and `n_estimators` values around the elbows of the graph. So, `max_depth` around 5, and `n_estimators` around 50.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yfEviQC5XeTb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CB0zPii6pYV3",
    "outputId": "09dd057c-7c91-4989-d268-b805c2f7c06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean test scores [-325.37889565 -284.00989898 -326.23933216 -326.21787578 -326.22011626]\n",
      "mean train scores [-306.47715345 -278.59774775 -306.47150171 -306.26970892 -306.49969652]\n",
      "Best Estimator:  RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=41, n_jobs=-1,\n",
      "                      oob_score=False, random_state=None, verbose=0,\n",
      "                      warm_start=False)\n",
      "Train MAPE:  0.12775629785820566\n",
      "Test MAPE:  0.12092945844983294\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\"n_estimators\":sp_randint(40,70),\n",
    "    \"max_depth\": sp_randint(4,7),\n",
    "    \"min_samples_split\": sp_randint(2, 5)}\n",
    "\n",
    "clf = RandomForestRegressor(n_jobs=-1)\n",
    "rf_random = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=5,scoring='neg_mean_squared_error',cv=10, return_train_score=True)\n",
    "rf_random.fit(df_train, tsne_train_output)\n",
    "print('mean test scores',rf_random.cv_results_['mean_test_score'])\n",
    "print('mean train scores',rf_random.cv_results_['mean_train_score'])\n",
    "\n",
    "clf = rf_random.best_estimator_\n",
    "\n",
    "print('Best Estimator: ', clf)\n",
    "\n",
    "clf.fit(df_train, tsne_train_output)\n",
    "y_train_pred = clf.predict(df_train)\n",
    "y_test_pred = clf.predict(df_test)\n",
    "\n",
    "print(\"Train MAPE: \", calc_MAPE(tsne_train_output,y_train_pred))\n",
    "print(\"Test MAPE: \", calc_MAPE(tsne_test_output,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "iAw-LW-PpYV5",
    "outputId": "c02fbbab-4a5f-436d-bc5e-74652cf0c091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ft_5', 'ft_4', 'ft_3', 'ft_2', 'ft_1', 'freq_0', 'amp_0', 'freq_1',\n",
      "       'amp_1', 'freq_2', 'amp_2', 'freq_3', 'amp_3', 'freq_4', 'amp_4', 'lat',\n",
      "       'lon', 'weekday', 'exp_avg', 'cluster_id'],\n",
      "      dtype='object')\n",
      "[2.74692769e-06 4.47063949e-05 7.34611639e-06 3.88654669e-06\n",
      " 6.60703543e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 9.93334279e-01 0.00000000e+00]\n",
      "Index(['exp_avg', 'ft_1', 'ft_4', 'ft_3', 'ft_2', 'ft_5', 'freq_0', 'amp_0',\n",
      "       'freq_1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#feature importances based on analysis using random forest\n",
    "print (df_train.columns)\n",
    "print (clf.feature_importances_)\n",
    "\n",
    "inds = np.argsort(clf.feature_importances_)\n",
    "imp_cols = df_train.columns[inds[None:-10:-1]]\n",
    "print(imp_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4p0IhKaSpYV6"
   },
   "source": [
    "### Using XgBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "colab_type": "code",
    "id": "nP3gp-0kpYV7",
    "outputId": "126a0b7f-f43e-4fc9-c8cb-27d25a288a15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Estimators =  10 Train Score 0.36788927885816347 test Score 0.3654381200688201\n",
      "[20:26:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Estimators =  50 Train Score 0.12608815449389313 test Score 0.11959402341755858\n",
      "[20:26:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Estimators =  100 Train Score 0.125303446022751 test Score 0.11925624463497128\n",
      "[20:26:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Estimators =  250 Train Score 0.12394196743860231 test Score 0.11829708356340835\n",
      "[20:27:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Estimators =  500 Train Score 0.12282390984398615 test Score 0.11772948576887897\n",
      "[20:28:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Estimators =  1000 Train Score 0.12150400946304023 test Score 0.11731681419788702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Estimators vs score')"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "estimators = [10,50,100,250, 500, 1000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in estimators:\n",
    "  clf = xgb.XGBRegressor(\n",
    "   learning_rate =0.1,\n",
    "   n_estimators=i,\n",
    "   max_depth=3,\n",
    "   min_child_weight=3,\n",
    "   gamma=0,\n",
    "   subsample=0.8,\n",
    "   reg_alpha=200, reg_lambda=200,\n",
    "   colsample_bytree=0.8,nthread=4)\n",
    "  clf.fit(df_train, tsne_train_output)\n",
    "  train_sc = calc_MAPE(tsne_train_output,clf.predict(df_train))\n",
    "  test_sc = calc_MAPE(tsne_test_output,clf.predict(df_test))\n",
    "  test_scores.append(test_sc)\n",
    "  train_scores.append(train_sc)\n",
    "  print('Estimators = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
    "plt.plot(estimators,train_scores,label='Train Score')\n",
    "plt.plot(estimators,test_scores,label='Test Score')\n",
    "plt.xlabel('Estimators')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Estimators vs score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "colab_type": "code",
    "id": "57jMsUJdELT9",
    "outputId": "a746c2ac-c0d3-4bbd-f9b8-077caaf5099e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Depths =  3 Train Score 0.12282390984398615 test Score 0.11772948576887897\n",
      "[20:31:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Depths =  5 Train Score 0.1195645236886165 test Score 0.11674756069142395\n",
      "[20:33:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Depths =  8 Train Score 0.11351458624880534 test Score 0.11668544898648527\n",
      "[20:36:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Depths =  10 Train Score 0.1083196457458951 test Score 0.11676210601079251\n",
      "[20:41:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Depths =  15 Train Score 0.09386031458921193 test Score 0.1174185924862408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Depths vs score')"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB9tcvEptsXzJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "depths = [3, 5, 8, 10, 15]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in depths:\n",
    "  clf = xgb.XGBRegressor(\n",
    "   learning_rate =0.1,\n",
    "   n_estimators=500,\n",
    "   max_depth=i,\n",
    "   min_child_weight=3,\n",
    "   gamma=0,\n",
    "   subsample=0.8,\n",
    "   reg_alpha=200, reg_lambda=200,\n",
    "   colsample_bytree=0.8,nthread=4)\n",
    "  clf.fit(df_train, tsne_train_output)\n",
    "  train_sc = calc_MAPE(tsne_train_output,clf.predict(df_train))\n",
    "  test_sc = calc_MAPE(tsne_test_output,clf.predict(df_test))\n",
    "  test_scores.append(test_sc)\n",
    "  train_scores.append(train_sc)\n",
    "  print('Depths = ',i,'Train Score',train_sc,'test Score',test_sc)\n",
    "plt.plot(depths,train_scores,label='Train Score')\n",
    "plt.plot(depths,test_scores,label='Test Score')\n",
    "plt.xlabel('Depths')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Depths vs score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XRTslBM-_5W6",
    "outputId": "8953cd7d-6b78-4e6e-a53e-55336d3e35fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:34:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:34:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:34:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:34:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:35:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:35:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:35:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:36:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:36:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:36:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:36:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:37:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:37:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:37:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:38:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:38:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:38:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:39:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:39:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:39:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:39:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:40:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:40:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:41:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:41:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:41:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:42:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:42:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:43:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:43:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:43:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:44:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:44:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:44:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:44:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:44:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:45:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:45:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:45:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:45:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:45:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:46:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:46:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:46:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:46:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:46:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:46:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:47:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:47:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:47:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:47:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "mean test scores [-356.7389414  -373.01542058 -357.75932091 -371.91452142 -336.10340613]\n",
      "mean train scores [-255.30896492 -247.72946075 -249.17872772 -267.54641259 -259.16311609]\n",
      "Best Estimator:  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
      "             importance_type='gain', learning_rate=0.1865401918732345,\n",
      "             max_delta_step=0, max_depth=5, min_child_weight=3, missing=None,\n",
      "             n_estimators=55, n_jobs=1, nthread=4, objective='reg:linear',\n",
      "             random_state=0, reg_alpha=200, reg_lambda=200, scale_pos_weight=1,\n",
      "             seed=None, silent=None, subsample=0.8, verbosity=1)\n",
      "[21:47:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Train MAPE:  0.12342634088042077\n",
      "Test MAPE:  0.11810948813003048\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\"n_estimators\":sp_randint(40,70),\n",
    "    \"max_depth\": sp_randint(5,9),\n",
    "   \"learning_rate\": uniform(0.08, 0.12)}\n",
    "\n",
    "clf = xgb.XGBRegressor(\n",
    "   min_child_weight=3,\n",
    "   gamma=0,\n",
    "   subsample=0.8,\n",
    "   reg_alpha=200, reg_lambda=200,\n",
    "   colsample_bytree=0.8,nthread=4)\n",
    "rf_random = RandomizedSearchCV(clf, param_distributions=param_dist,n_iter=5,scoring='neg_mean_squared_error',cv=10, return_train_score=True)\n",
    "rf_random.fit(df_train, tsne_train_output)\n",
    "print('mean test scores',rf_random.cv_results_['mean_test_score'])\n",
    "print('mean train scores',rf_random.cv_results_['mean_train_score'])\n",
    "\n",
    "clf = rf_random.best_estimator_\n",
    "\n",
    "print('Best Estimator: ', clf)\n",
    "\n",
    "clf.fit(df_train, tsne_train_output)\n",
    "y_train_pred = clf.predict(df_train)\n",
    "y_test_pred = clf.predict(df_test)\n",
    "\n",
    "print(\"Train MAPE: \", calc_MAPE(tsne_train_output,y_train_pred))\n",
    "print(\"Test MAPE: \", calc_MAPE(tsne_test_output,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previous code cell's output is copied to markdown cell below as there are lot of deprecated warnings which are printed before the main output.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>mean test scores [-356.7389414  -373.01542058 -357.75932091 -371.91452142 -336.10340613]\n",
    "    \n",
    "mean train scores [-255.30896492 -247.72946075 -249.17872772 -267.54641259 -259.16311609]</b>\n",
    "<br>\n",
    "<br>\n",
    "<b>Best Estimator:  XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.8, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.1865401918732345,\n",
    "             max_delta_step=0, max_depth=5, min_child_weight=3, missing=None,\n",
    "             n_estimators=55, n_jobs=1, nthread=4, objective='reg:linear',\n",
    "             random_state=0, reg_alpha=200, reg_lambda=200, scale_pos_weight=1,\n",
    "             seed=None, silent=None, subsample=0.8, verbosity=1)\n",
    "\n",
    "Train MAPE:  0.12342634088042077\n",
    "\n",
    "Test MAPE:  0.11810948813003048</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "JUA9-V_Qy18p",
    "outputId": "c83c8106-8758-4578-ba67-07b25a88991d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.98805782e-04, 4.98338020e-04, 3.75492312e-03, 1.88882221e-02,\n",
       "       2.63216078e-01, 0.00000000e+00, 4.86344274e-04, 1.41845565e-04,\n",
       "       3.44068947e-04, 1.80868126e-04, 1.74489905e-04, 4.80664239e-05,\n",
       "       1.16007854e-04, 2.16440938e-04, 1.88977196e-04, 4.30918386e-04,\n",
       "       5.04031486e-04, 1.84068573e-04, 7.09724247e-01, 3.03326320e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "vZMtoJZzAZqu",
    "outputId": "e7e828d0-812a-40a6-ab04-66d4d65a0b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ft_5', 'ft_4', 'ft_3', 'ft_2', 'ft_1', 'freq_0', 'amp_0', 'freq_1',\n",
      "       'amp_1', 'freq_2', 'amp_2', 'freq_3', 'amp_3', 'freq_4', 'amp_4', 'lat',\n",
      "       'lon', 'weekday', 'exp_avg', 'cluster_id'],\n",
      "      dtype='object')\n",
      "[5.98805782e-04 4.98338020e-04 3.75492312e-03 1.88882221e-02\n",
      " 2.63216078e-01 0.00000000e+00 4.86344274e-04 1.41845565e-04\n",
      " 3.44068947e-04 1.80868126e-04 1.74489905e-04 4.80664239e-05\n",
      " 1.16007854e-04 2.16440938e-04 1.88977196e-04 4.30918386e-04\n",
      " 5.04031486e-04 1.84068573e-04 7.09724247e-01 3.03326320e-04]\n",
      "Index(['exp_avg', 'ft_1', 'ft_2', 'ft_3', 'ft_5', 'lon', 'ft_4', 'amp_0',\n",
      "       'lat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#feature importances based on analysis using random forest\n",
    "print (df_train.columns)\n",
    "print (clf.feature_importances_)\n",
    "\n",
    "inds = np.argsort(clf.feature_importances_)\n",
    "imp_cols = df_train.columns[inds[None:-10:-1]]\n",
    "print(imp_cols)\n",
    "# inds = np.argsort(clf.feature_importances_)\n",
    "# imp_cols = clf.columns[inds[None:-5:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NcTyUQveXoZ7"
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Printing a Table with MAPE values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------------------------------------+------------+-----------+\n",
      "|       Model       |                    hyper-parameters                   | Train MAPE | Test MAPE |\n",
      "+-------------------+-------------------------------------------------------+------------+-----------+\n",
      "| Linear Regression |                          None                         | 12.5306 %  | 11.9048 % |\n",
      "|   Random Forest   |         n_estimators: 250, min_sample_slit: 4         |  4.894 %   | 11.7147 % |\n",
      "|   Random Forest   |            n_estimators: 40, max_depth: 20            |  9.0845 %  |  11.726 % |\n",
      "|   Random Forest   |  n_estimators: 41, max_depth: 5, min_sample_split: 2  | 12.7756 %  |  12.093 % |\n",
      "|      XGBoost      |            n_estimators: 1000, max_depth: 3           | 12.1504 %  | 11.7317 % |\n",
      "|      XGBoost      |            n_estimators: 500, max_depth: 8            | 11.3514 %  | 11.6685 % |\n",
      "|      XGBoost      | n_estimators: 55, max_depth: 5, learning_rate: 0.1865 | 12.3426 %  | 11.8109 % |\n",
      "+-------------------+-------------------------------------------------------+------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "\n",
    "table.field_names = ['Model', 'hyper-parameters', 'Train MAPE', 'Test MAPE']\n",
    "table.add_row(['Linear Regression', 'None', '12.5306 %', '11.9048 %'])\n",
    "table.add_row(['Random Forest', 'n_estimators: 250, min_sample_slit: 4', '4.894 %', '11.7147 %'])\n",
    "table.add_row(['Random Forest', 'n_estimators: 40, max_depth: 20', '9.0845 %', '11.726 %'])\n",
    "table.add_row(['Random Forest', 'n_estimators: 41, max_depth: 5, min_sample_split: 2', '12.7756 %', '12.093 %'])\n",
    "table.add_row(['XGBoost', 'n_estimators: 1000, max_depth: 3', '12.1504 %', '11.7317 %'])\n",
    "table.add_row(['XGBoost', 'n_estimators: 500, max_depth: 8', '11.3514 %', '11.6685 %'])\n",
    "table.add_row(['XGBoost', 'n_estimators: 55, max_depth: 5, learning_rate: 0.1865', '12.3426 %', '11.8109 %'])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In above models, sklearn's LinearRegression doesnt have any hyper-parameters to tune so there are None. For Random Forest, remaining hyper-parameters which are not mentioned here are default values of the sklearn's Random Forest. For XGBoost, remaining hyper-parameters which are not mentioned here are taken from the original notebook's XGBoost model. Hyper-parameters of third Random Forest model and XGBoost model are tuned using sklearn's RandomSearchCV.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "- **Among all models XGBoost with n_estimators: 500 and max_depth: 8 gave very good results. And also Random Forest model with n_estimators: 40 and max_depth: 20 gave good results.**\n",
    "- **The training data is one-hot encoded before passing it to Linear regression model as the cluster centers and weekday are not linearly dependent on the output i.e. number of cabs booked. For tree based models encoding is not done as they can handle non-linear relation between input and output and also tree based models will not perform good with high-dimentional data and sparse data.**\n",
    "- **Random Forest models for which max-depth is not tuned are overfitting a lot.**\n",
    "- **When important features abserved in both Random forest and XGBoost exponential moving average output and previous 10-min intervals data seems to be very important. And in XGBoost we can see latitude data and longitude data and a fourier data (amplitude of highest frequency) seems to be important. Below I print top features for both models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important features for Random Forest: ['exp_avg', 'ft_1', 'ft_4', 'ft_3', 'ft_2', 'ft_5']**\n",
    "\n",
    "**Important features for XGBoost: ['exp_avg', 'ft_1', 'ft_2', 'ft_3', 'ft_5', 'lon', 'ft_4', 'amp_0', 'lat']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of NYC Final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
